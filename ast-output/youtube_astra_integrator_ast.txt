AST for temp_dir\ARTGuru-AI-main\python_webscraper_integarted_with_astradb\youtube_astra_integrator.py
==================================================
module [import os
import json
import time
from datetime import datetime
import googleapiclient.discovery
import googleapiclient.errors
from pathlib import Path
import pandas as pd
import numpy as np
from astrapy import DataAPIClient
from dotenv import load_dotenv


class YouTubeAstraIntegrator:
    def __init__(self, youtube_api_key, astra_token, astra_endpoint, collection_name="youtube_data",
                 output_dir='youtube_data'):
        """
        Initialize YouTube scraper and AstraDB uploader.
        """
        # Initialize YouTube API client
        if not youtube_api_key:
            raise ValueError("YouTube API key is required")

        try:
            self.youtube = googleapiclient.discovery.build(
                "youtube", "v3", developerKey=youtube_api_key
            )
        except Exception as e:
            print(f"Error initializing YouTube API client: {e}")
            self.youtube = None

        # Initialize AstraDB client
        self.client = DataAPIClient(astra_token)
        self.db = self.client.get_database_by_api_endpoint(astra_endpoint)
        self.collection = self.db[collection_name]
        self.vector_dim = 1536

        # Create output directory
        self.data_dir = Path(output_dir)
        self.data_dir.mkdir(exist_ok=True)

        print(f"Connected to YouTube API and Astra DB collection: {collection_name}")

    def create_vector(self, text):
        """Create normalized vector for text embedding."""
        vector = np.random.normal(0, 1, self.vector_dim)
        normalized_vector = vector / np.linalg.norm(vector)
        return normalized_vector.tolist()

    def prepare_document(self, video_data):
        """Prepare video data for AstraDB storage."""
        try:
            # Create a simpler text content for vector creation
            title = video_data.get('title', '')[:1000]
            description = video_data.get('description', '')[:3000]

            comment_texts = []
            for comment in video_data.get('comments', [])[:5]:
                comment_text = comment.get('text', '')[:500]
                comment_texts.append(comment_text)

            text_content = f"{title} {description} {' '.join(comment_texts)}"

            content_bytes = text_content.encode('utf-8')
            if len(content_bytes) > 8000:
                content_bytes = content_bytes[:8000]
                text_content = content_bytes.decode('utf-8', errors='ignore')

            metadata = {
                'video_id': video_data.get('video_id', ''),
                'title': title,
                'channel_title': video_data.get('channel_title', '')[:100],
                'view_count': video_data.get('view_count', 0),
                'like_count': video_data.get('like_count', 0),
                'comment_count': video_data.get('comment_count', 0),
                'published_at': video_data.get('published_at', ''),
                'scraped_at': datetime.now().isoformat(),
                'comments': [{'text': t[:500], 'author': c.get('author', '')[:100]}
                             for t, c in zip(comment_texts, video_data.get('comments', [])[:5])]
            }

            document = {
                'content': text_content,
                'metadata': metadata,
                '$vector': self.create_vector(text_content)
            }

            return document
        except Exception as e:
            print(f"Error preparing document: {e}")
            return None

    def get_video_comments(self, video_id, max_comments=50):
        """Get comments for a video."""
        comments = []
        try:
            request = self.youtube.commentThreads().list(
                part="snippet",
                videoId=video_id,
                maxResults=min(max_comments, 100)
            )

            while request and len(comments) < max_comments:
                response = request.execute()

                for item in response['items']:
                    comment = item['snippet']['topLevelComment']['snippet']
                    comment_data = {
                        'author': comment['authorDisplayName'],
                        'text': comment['textDisplay'],
                        'like_count': comment['likeCount'],
                        'published_at': comment['publishedAt']
                    }
                    comments.append(comment_data)

                request = self.youtube.commentThreads().list_next(request, response)

        except Exception as e:
            print(f"Error fetching comments: {e}")

        return comments

    def _save_data(self, data, prefix):
        """Save local copy of data."""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        json_file = self.data_dir / f'{prefix}_{timestamp}.json'
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

        try:
            flat_data = {
                'video_id': data['video_id'],
                'title': data['title'],
                'channel_title': data['channel_title'],
                'view_count': data['view_count'],
                'like_count': data['like_count'],
                'comment_count': data['comment_count'],
                'published_at': data['published_at']
            }

            csv_file = self.data_dir / f'{prefix}_{timestamp}.csv'
            pd.DataFrame([flat_data]).to_csv(csv_file, index=False)

            print(f"Data saved to {json_file} and {csv_file}")
        except Exception as e:
            print(f"Error saving CSV: {e}")] (0:0-146:43)
  import_statement [import os] (0:0-0:9)
    import [import] (0:0-0:6)
    dotted_name [os] (0:7-0:9)
      identifier [os] (0:7-0:9)
  import_statement [import json] (1:0-1:11)
    import [import] (1:0-1:6)
    dotted_name [json] (1:7-1:11)
      identifier [json] (1:7-1:11)
  import_statement [import time] (2:0-2:11)
    import [import] (2:0-2:6)
    dotted_name [time] (2:7-2:11)
      identifier [time] (2:7-2:11)
  import_from_statement [from datetime import datetime] (3:0-3:29)
    from [from] (3:0-3:4)
    dotted_name [datetime] (3:5-3:13)
      identifier [datetime] (3:5-3:13)
    import [import] (3:14-3:20)
    dotted_name [datetime] (3:21-3:29)
      identifier [datetime] (3:21-3:29)
  import_statement [import googleapiclient.discovery] (4:0-4:32)
    import [import] (4:0-4:6)
    dotted_name [googleapiclient.discovery] (4:7-4:32)
      identifier [googleapiclient] (4:7-4:22)
      . [.] (4:22-4:23)
      identifier [discovery] (4:23-4:32)
  import_statement [import googleapiclient.errors] (5:0-5:29)
    import [import] (5:0-5:6)
    dotted_name [googleapiclient.errors] (5:7-5:29)
      identifier [googleapiclient] (5:7-5:22)
      . [.] (5:22-5:23)
      identifier [errors] (5:23-5:29)
  import_from_statement [from pathlib import Path] (6:0-6:24)
    from [from] (6:0-6:4)
    dotted_name [pathlib] (6:5-6:12)
      identifier [pathlib] (6:5-6:12)
    import [import] (6:13-6:19)
    dotted_name [Path] (6:20-6:24)
      identifier [Path] (6:20-6:24)
  import_statement [import pandas as pd] (7:0-7:19)
    import [import] (7:0-7:6)
    aliased_import [pandas as pd] (7:7-7:19)
      dotted_name [pandas] (7:7-7:13)
        identifier [pandas] (7:7-7:13)
      as [as] (7:14-7:16)
      identifier [pd] (7:17-7:19)
  import_statement [import numpy as np] (8:0-8:18)
    import [import] (8:0-8:6)
    aliased_import [numpy as np] (8:7-8:18)
      dotted_name [numpy] (8:7-8:12)
        identifier [numpy] (8:7-8:12)
      as [as] (8:13-8:15)
      identifier [np] (8:16-8:18)
  import_from_statement [from astrapy import DataAPIClient] (9:0-9:33)
    from [from] (9:0-9:4)
    dotted_name [astrapy] (9:5-9:12)
      identifier [astrapy] (9:5-9:12)
    import [import] (9:13-9:19)
    dotted_name [DataAPIClient] (9:20-9:33)
      identifier [DataAPIClient] (9:20-9:33)
  import_from_statement [from dotenv import load_dotenv] (10:0-10:30)
    from [from] (10:0-10:4)
    dotted_name [dotenv] (10:5-10:11)
      identifier [dotenv] (10:5-10:11)
    import [import] (10:12-10:18)
    dotted_name [load_dotenv] (10:19-10:30)
      identifier [load_dotenv] (10:19-10:30)
  class_definition [class YouTubeAstraIntegrator:
    def __init__(self, youtube_api_key, astra_token, astra_endpoint, collection_name="youtube_data",
                 output_dir='youtube_data'):
        """
        Initialize YouTube scraper and AstraDB uploader.
        """
        # Initialize YouTube API client
        if not youtube_api_key:
            raise ValueError("YouTube API key is required")

        try:
            self.youtube = googleapiclient.discovery.build(
                "youtube", "v3", developerKey=youtube_api_key
            )
        except Exception as e:
            print(f"Error initializing YouTube API client: {e}")
            self.youtube = None

        # Initialize AstraDB client
        self.client = DataAPIClient(astra_token)
        self.db = self.client.get_database_by_api_endpoint(astra_endpoint)
        self.collection = self.db[collection_name]
        self.vector_dim = 1536

        # Create output directory
        self.data_dir = Path(output_dir)
        self.data_dir.mkdir(exist_ok=True)

        print(f"Connected to YouTube API and Astra DB collection: {collection_name}")

    def create_vector(self, text):
        """Create normalized vector for text embedding."""
        vector = np.random.normal(0, 1, self.vector_dim)
        normalized_vector = vector / np.linalg.norm(vector)
        return normalized_vector.tolist()

    def prepare_document(self, video_data):
        """Prepare video data for AstraDB storage."""
        try:
            # Create a simpler text content for vector creation
            title = video_data.get('title', '')[:1000]
            description = video_data.get('description', '')[:3000]

            comment_texts = []
            for comment in video_data.get('comments', [])[:5]:
                comment_text = comment.get('text', '')[:500]
                comment_texts.append(comment_text)

            text_content = f"{title} {description} {' '.join(comment_texts)}"

            content_bytes = text_content.encode('utf-8')
            if len(content_bytes) > 8000:
                content_bytes = content_bytes[:8000]
                text_content = content_bytes.decode('utf-8', errors='ignore')

            metadata = {
                'video_id': video_data.get('video_id', ''),
                'title': title,
                'channel_title': video_data.get('channel_title', '')[:100],
                'view_count': video_data.get('view_count', 0),
                'like_count': video_data.get('like_count', 0),
                'comment_count': video_data.get('comment_count', 0),
                'published_at': video_data.get('published_at', ''),
                'scraped_at': datetime.now().isoformat(),
                'comments': [{'text': t[:500], 'author': c.get('author', '')[:100]}
                             for t, c in zip(comment_texts, video_data.get('comments', [])[:5])]
            }

            document = {
                'content': text_content,
                'metadata': metadata,
                '$vector': self.create_vector(text_content)
            }

            return document
        except Exception as e:
            print(f"Error preparing document: {e}")
            return None

    def get_video_comments(self, video_id, max_comments=50):
        """Get comments for a video."""
        comments = []
        try:
            request = self.youtube.commentThreads().list(
                part="snippet",
                videoId=video_id,
                maxResults=min(max_comments, 100)
            )

            while request and len(comments) < max_comments:
                response = request.execute()

                for item in response['items']:
                    comment = item['snippet']['topLevelComment']['snippet']
                    comment_data = {
                        'author': comment['authorDisplayName'],
                        'text': comment['textDisplay'],
                        'like_count': comment['likeCount'],
                        'published_at': comment['publishedAt']
                    }
                    comments.append(comment_data)

                request = self.youtube.commentThreads().list_next(request, response)

        except Exception as e:
            print(f"Error fetching comments: {e}")

        return comments

    def _save_data(self, data, prefix):
        """Save local copy of data."""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        json_file = self.data_dir / f'{prefix}_{timestamp}.json'
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

        try:
            flat_data = {
                'video_id': data['video_id'],
                'title': data['title'],
                'channel_title': data['channel_title'],
                'view_count': data['view_count'],
                'like_count': data['like_count'],
                'comment_count': data['comment_count'],
                'published_at': data['published_at']
            }

            csv_file = self.data_dir / f'{prefix}_{timestamp}.csv'
            pd.DataFrame([flat_data]).to_csv(csv_file, index=False)

            print(f"Data saved to {json_file} and {csv_file}")
        except Exception as e:
            print(f"Error saving CSV: {e}")] (13:0-146:43)
    class [class] (13:0-13:5)
    identifier [YouTubeAstraIntegrator] (13:6-13:28)
    : [:] (13:28-13:29)
    block [def __init__(self, youtube_api_key, astra_token, astra_endpoint, collection_name="youtube_data",
                 output_dir='youtube_data'):
        """
        Initialize YouTube scraper and AstraDB uploader.
        """
        # Initialize YouTube API client
        if not youtube_api_key:
            raise ValueError("YouTube API key is required")

        try:
            self.youtube = googleapiclient.discovery.build(
                "youtube", "v3", developerKey=youtube_api_key
            )
        except Exception as e:
            print(f"Error initializing YouTube API client: {e}")
            self.youtube = None

        # Initialize AstraDB client
        self.client = DataAPIClient(astra_token)
        self.db = self.client.get_database_by_api_endpoint(astra_endpoint)
        self.collection = self.db[collection_name]
        self.vector_dim = 1536

        # Create output directory
        self.data_dir = Path(output_dir)
        self.data_dir.mkdir(exist_ok=True)

        print(f"Connected to YouTube API and Astra DB collection: {collection_name}")

    def create_vector(self, text):
        """Create normalized vector for text embedding."""
        vector = np.random.normal(0, 1, self.vector_dim)
        normalized_vector = vector / np.linalg.norm(vector)
        return normalized_vector.tolist()

    def prepare_document(self, video_data):
        """Prepare video data for AstraDB storage."""
        try:
            # Create a simpler text content for vector creation
            title = video_data.get('title', '')[:1000]
            description = video_data.get('description', '')[:3000]

            comment_texts = []
            for comment in video_data.get('comments', [])[:5]:
                comment_text = comment.get('text', '')[:500]
                comment_texts.append(comment_text)

            text_content = f"{title} {description} {' '.join(comment_texts)}"

            content_bytes = text_content.encode('utf-8')
            if len(content_bytes) > 8000:
                content_bytes = content_bytes[:8000]
                text_content = content_bytes.decode('utf-8', errors='ignore')

            metadata = {
                'video_id': video_data.get('video_id', ''),
                'title': title,
                'channel_title': video_data.get('channel_title', '')[:100],
                'view_count': video_data.get('view_count', 0),
                'like_count': video_data.get('like_count', 0),
                'comment_count': video_data.get('comment_count', 0),
                'published_at': video_data.get('published_at', ''),
                'scraped_at': datetime.now().isoformat(),
                'comments': [{'text': t[:500], 'author': c.get('author', '')[:100]}
                             for t, c in zip(comment_texts, video_data.get('comments', [])[:5])]
            }

            document = {
                'content': text_content,
                'metadata': metadata,
                '$vector': self.create_vector(text_content)
            }

            return document
        except Exception as e:
            print(f"Error preparing document: {e}")
            return None

    def get_video_comments(self, video_id, max_comments=50):
        """Get comments for a video."""
        comments = []
        try:
            request = self.youtube.commentThreads().list(
                part="snippet",
                videoId=video_id,
                maxResults=min(max_comments, 100)
            )

            while request and len(comments) < max_comments:
                response = request.execute()

                for item in response['items']:
                    comment = item['snippet']['topLevelComment']['snippet']
                    comment_data = {
                        'author': comment['authorDisplayName'],
                        'text': comment['textDisplay'],
                        'like_count': comment['likeCount'],
                        'published_at': comment['publishedAt']
                    }
                    comments.append(comment_data)

                request = self.youtube.commentThreads().list_next(request, response)

        except Exception as e:
            print(f"Error fetching comments: {e}")

        return comments

    def _save_data(self, data, prefix):
        """Save local copy of data."""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        json_file = self.data_dir / f'{prefix}_{timestamp}.json'
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

        try:
            flat_data = {
                'video_id': data['video_id'],
                'title': data['title'],
                'channel_title': data['channel_title'],
                'view_count': data['view_count'],
                'like_count': data['like_count'],
                'comment_count': data['comment_count'],
                'published_at': data['published_at']
            }

            csv_file = self.data_dir / f'{prefix}_{timestamp}.csv'
            pd.DataFrame([flat_data]).to_csv(csv_file, index=False)

            print(f"Data saved to {json_file} and {csv_file}")
        except Exception as e:
            print(f"Error saving CSV: {e}")] (14:4-146:43)
      function_definition [def __init__(self, youtube_api_key, astra_token, astra_endpoint, collection_name="youtube_data",
                 output_dir='youtube_data'):
        """
        Initialize YouTube scraper and AstraDB uploader.
        """
        # Initialize YouTube API client
        if not youtube_api_key:
            raise ValueError("YouTube API key is required")

        try:
            self.youtube = googleapiclient.discovery.build(
                "youtube", "v3", developerKey=youtube_api_key
            )
        except Exception as e:
            print(f"Error initializing YouTube API client: {e}")
            self.youtube = None

        # Initialize AstraDB client
        self.client = DataAPIClient(astra_token)
        self.db = self.client.get_database_by_api_endpoint(astra_endpoint)
        self.collection = self.db[collection_name]
        self.vector_dim = 1536

        # Create output directory
        self.data_dir = Path(output_dir)
        self.data_dir.mkdir(exist_ok=True)

        print(f"Connected to YouTube API and Astra DB collection: {collection_name}")] (14:4-41:85)
        def [def] (14:4-14:7)
        identifier [__init__] (14:8-14:16)
        parameters [(self, youtube_api_key, astra_token, astra_endpoint, collection_name="youtube_data",
                 output_dir='youtube_data')] (14:16-15:43)
          ( [(] (14:16-14:17)
          identifier [self] (14:17-14:21)
          , [,] (14:21-14:22)
          identifier [youtube_api_key] (14:23-14:38)
          , [,] (14:38-14:39)
          identifier [astra_token] (14:40-14:51)
          , [,] (14:51-14:52)
          identifier [astra_endpoint] (14:53-14:67)
          , [,] (14:67-14:68)
          default_parameter [collection_name="youtube_data"] (14:69-14:99)
            identifier [collection_name] (14:69-14:84)
            = [=] (14:84-14:85)
            string ["youtube_data"] (14:85-14:99)
              string_start ["] (14:85-14:86)
              string_content [youtube_data] (14:86-14:98)
              string_end ["] (14:98-14:99)
          , [,] (14:99-14:100)
          default_parameter [output_dir='youtube_data'] (15:17-15:42)
            identifier [output_dir] (15:17-15:27)
            = [=] (15:27-15:28)
            string ['youtube_data'] (15:28-15:42)
              string_start ['] (15:28-15:29)
              string_content [youtube_data] (15:29-15:41)
              string_end ['] (15:41-15:42)
          ) [)] (15:42-15:43)
        : [:] (15:43-15:44)
        block ["""
        Initialize YouTube scraper and AstraDB uploader.
        """
        # Initialize YouTube API client
        if not youtube_api_key:
            raise ValueError("YouTube API key is required")

        try:
            self.youtube = googleapiclient.discovery.build(
                "youtube", "v3", developerKey=youtube_api_key
            )
        except Exception as e:
            print(f"Error initializing YouTube API client: {e}")
            self.youtube = None

        # Initialize AstraDB client
        self.client = DataAPIClient(astra_token)
        self.db = self.client.get_database_by_api_endpoint(astra_endpoint)
        self.collection = self.db[collection_name]
        self.vector_dim = 1536

        # Create output directory
        self.data_dir = Path(output_dir)
        self.data_dir.mkdir(exist_ok=True)

        print(f"Connected to YouTube API and Astra DB collection: {collection_name}")] (16:8-41:85)
          expression_statement ["""
        Initialize YouTube scraper and AstraDB uploader.
        """] (16:8-18:11)
            string ["""
        Initialize YouTube scraper and AstraDB uploader.
        """] (16:8-18:11)
              string_start ["""] (16:8-16:11)
              string_content [
        Initialize YouTube scraper and AstraDB uploader.
        ] (16:11-18:8)
              string_end ["""] (18:8-18:11)
          comment [# Initialize YouTube API client] (19:8-19:39)
          if_statement [if not youtube_api_key:
            raise ValueError("YouTube API key is required")] (20:8-21:59)
            if [if] (20:8-20:10)
            not_operator [not youtube_api_key] (20:11-20:30)
              not [not] (20:11-20:14)
              identifier [youtube_api_key] (20:15-20:30)
            : [:] (20:30-20:31)
            block [raise ValueError("YouTube API key is required")] (21:12-21:59)
              raise_statement [raise ValueError("YouTube API key is required")] (21:12-21:59)
                raise [raise] (21:12-21:17)
                call [ValueError("YouTube API key is required")] (21:18-21:59)
                  identifier [ValueError] (21:18-21:28)
                  argument_list [("YouTube API key is required")] (21:28-21:59)
                    ( [(] (21:28-21:29)
                    string ["YouTube API key is required"] (21:29-21:58)
                      string_start ["] (21:29-21:30)
                      string_content [YouTube API key is required] (21:30-21:57)
                      string_end ["] (21:57-21:58)
                    ) [)] (21:58-21:59)
          try_statement [try:
            self.youtube = googleapiclient.discovery.build(
                "youtube", "v3", developerKey=youtube_api_key
            )
        except Exception as e:
            print(f"Error initializing YouTube API client: {e}")
            self.youtube = None] (23:8-29:31)
            try [try] (23:8-23:11)
            : [:] (23:11-23:12)
            block [self.youtube = googleapiclient.discovery.build(
                "youtube", "v3", developerKey=youtube_api_key
            )] (24:12-26:13)
              expression_statement [self.youtube = googleapiclient.discovery.build(
                "youtube", "v3", developerKey=youtube_api_key
            )] (24:12-26:13)
                assignment [self.youtube = googleapiclient.discovery.build(
                "youtube", "v3", developerKey=youtube_api_key
            )] (24:12-26:13)
                  attribute [self.youtube] (24:12-24:24)
                    identifier [self] (24:12-24:16)
                    . [.] (24:16-24:17)
                    identifier [youtube] (24:17-24:24)
                  = [=] (24:25-24:26)
                  call [googleapiclient.discovery.build(
                "youtube", "v3", developerKey=youtube_api_key
            )] (24:27-26:13)
                    attribute [googleapiclient.discovery.build] (24:27-24:58)
                      attribute [googleapiclient.discovery] (24:27-24:52)
                        identifier [googleapiclient] (24:27-24:42)
                        . [.] (24:42-24:43)
                        identifier [discovery] (24:43-24:52)
                      . [.] (24:52-24:53)
                      identifier [build] (24:53-24:58)
                    argument_list [(
                "youtube", "v3", developerKey=youtube_api_key
            )] (24:58-26:13)
                      ( [(] (24:58-24:59)
                      string ["youtube"] (25:16-25:25)
                        string_start ["] (25:16-25:17)
                        string_content [youtube] (25:17-25:24)
                        string_end ["] (25:24-25:25)
                      , [,] (25:25-25:26)
                      string ["v3"] (25:27-25:31)
                        string_start ["] (25:27-25:28)
                        string_content [v3] (25:28-25:30)
                        string_end ["] (25:30-25:31)
                      , [,] (25:31-25:32)
                      keyword_argument [developerKey=youtube_api_key] (25:33-25:61)
                        identifier [developerKey] (25:33-25:45)
                        = [=] (25:45-25:46)
                        identifier [youtube_api_key] (25:46-25:61)
                      ) [)] (26:12-26:13)
            except_clause [except Exception as e:
            print(f"Error initializing YouTube API client: {e}")
            self.youtube = None] (27:8-29:31)
              except [except] (27:8-27:14)
              as_pattern [Exception as e] (27:15-27:29)
                identifier [Exception] (27:15-27:24)
                as [as] (27:25-27:27)
                as_pattern_target [e] (27:28-27:29)
                  identifier [e] (27:28-27:29)
              : [:] (27:29-27:30)
              block [print(f"Error initializing YouTube API client: {e}")
            self.youtube = None] (28:12-29:31)
                expression_statement [print(f"Error initializing YouTube API client: {e}")] (28:12-28:64)
                  call [print(f"Error initializing YouTube API client: {e}")] (28:12-28:64)
                    identifier [print] (28:12-28:17)
                    argument_list [(f"Error initializing YouTube API client: {e}")] (28:17-28:64)
                      ( [(] (28:17-28:18)
                      string [f"Error initializing YouTube API client: {e}"] (28:18-28:63)
                        string_start [f"] (28:18-28:20)
                        string_content [Error initializing YouTube API client: ] (28:20-28:59)
                        interpolation [{e}] (28:59-28:62)
                          { [{] (28:59-28:60)
                          identifier [e] (28:60-28:61)
                          } [}] (28:61-28:62)
                        string_end ["] (28:62-28:63)
                      ) [)] (28:63-28:64)
                expression_statement [self.youtube = None] (29:12-29:31)
                  assignment [self.youtube = None] (29:12-29:31)
                    attribute [self.youtube] (29:12-29:24)
                      identifier [self] (29:12-29:16)
                      . [.] (29:16-29:17)
                      identifier [youtube] (29:17-29:24)
                    = [=] (29:25-29:26)
                    none [None] (29:27-29:31)
          comment [# Initialize AstraDB client] (31:8-31:35)
          expression_statement [self.client = DataAPIClient(astra_token)] (32:8-32:48)
            assignment [self.client = DataAPIClient(astra_token)] (32:8-32:48)
              attribute [self.client] (32:8-32:19)
                identifier [self] (32:8-32:12)
                . [.] (32:12-32:13)
                identifier [client] (32:13-32:19)
              = [=] (32:20-32:21)
              call [DataAPIClient(astra_token)] (32:22-32:48)
                identifier [DataAPIClient] (32:22-32:35)
                argument_list [(astra_token)] (32:35-32:48)
                  ( [(] (32:35-32:36)
                  identifier [astra_token] (32:36-32:47)
                  ) [)] (32:47-32:48)
          expression_statement [self.db = self.client.get_database_by_api_endpoint(astra_endpoint)] (33:8-33:74)
            assignment [self.db = self.client.get_database_by_api_endpoint(astra_endpoint)] (33:8-33:74)
              attribute [self.db] (33:8-33:15)
                identifier [self] (33:8-33:12)
                . [.] (33:12-33:13)
                identifier [db] (33:13-33:15)
              = [=] (33:16-33:17)
              call [self.client.get_database_by_api_endpoint(astra_endpoint)] (33:18-33:74)
                attribute [self.client.get_database_by_api_endpoint] (33:18-33:58)
                  attribute [self.client] (33:18-33:29)
                    identifier [self] (33:18-33:22)
                    . [.] (33:22-33:23)
                    identifier [client] (33:23-33:29)
                  . [.] (33:29-33:30)
                  identifier [get_database_by_api_endpoint] (33:30-33:58)
                argument_list [(astra_endpoint)] (33:58-33:74)
                  ( [(] (33:58-33:59)
                  identifier [astra_endpoint] (33:59-33:73)
                  ) [)] (33:73-33:74)
          expression_statement [self.collection = self.db[collection_name]] (34:8-34:50)
            assignment [self.collection = self.db[collection_name]] (34:8-34:50)
              attribute [self.collection] (34:8-34:23)
                identifier [self] (34:8-34:12)
                . [.] (34:12-34:13)
                identifier [collection] (34:13-34:23)
              = [=] (34:24-34:25)
              subscript [self.db[collection_name]] (34:26-34:50)
                attribute [self.db] (34:26-34:33)
                  identifier [self] (34:26-34:30)
                  . [.] (34:30-34:31)
                  identifier [db] (34:31-34:33)
                [ [[] (34:33-34:34)
                identifier [collection_name] (34:34-34:49)
                ] []] (34:49-34:50)
          expression_statement [self.vector_dim = 1536] (35:8-35:30)
            assignment [self.vector_dim = 1536] (35:8-35:30)
              attribute [self.vector_dim] (35:8-35:23)
                identifier [self] (35:8-35:12)
                . [.] (35:12-35:13)
                identifier [vector_dim] (35:13-35:23)
              = [=] (35:24-35:25)
              integer [1536] (35:26-35:30)
          comment [# Create output directory] (37:8-37:33)
          expression_statement [self.data_dir = Path(output_dir)] (38:8-38:40)
            assignment [self.data_dir = Path(output_dir)] (38:8-38:40)
              attribute [self.data_dir] (38:8-38:21)
                identifier [self] (38:8-38:12)
                . [.] (38:12-38:13)
                identifier [data_dir] (38:13-38:21)
              = [=] (38:22-38:23)
              call [Path(output_dir)] (38:24-38:40)
                identifier [Path] (38:24-38:28)
                argument_list [(output_dir)] (38:28-38:40)
                  ( [(] (38:28-38:29)
                  identifier [output_dir] (38:29-38:39)
                  ) [)] (38:39-38:40)
          expression_statement [self.data_dir.mkdir(exist_ok=True)] (39:8-39:42)
            call [self.data_dir.mkdir(exist_ok=True)] (39:8-39:42)
              attribute [self.data_dir.mkdir] (39:8-39:27)
                attribute [self.data_dir] (39:8-39:21)
                  identifier [self] (39:8-39:12)
                  . [.] (39:12-39:13)
                  identifier [data_dir] (39:13-39:21)
                . [.] (39:21-39:22)
                identifier [mkdir] (39:22-39:27)
              argument_list [(exist_ok=True)] (39:27-39:42)
                ( [(] (39:27-39:28)
                keyword_argument [exist_ok=True] (39:28-39:41)
                  identifier [exist_ok] (39:28-39:36)
                  = [=] (39:36-39:37)
                  true [True] (39:37-39:41)
                ) [)] (39:41-39:42)
          expression_statement [print(f"Connected to YouTube API and Astra DB collection: {collection_name}")] (41:8-41:85)
            call [print(f"Connected to YouTube API and Astra DB collection: {collection_name}")] (41:8-41:85)
              identifier [print] (41:8-41:13)
              argument_list [(f"Connected to YouTube API and Astra DB collection: {collection_name}")] (41:13-41:85)
                ( [(] (41:13-41:14)
                string [f"Connected to YouTube API and Astra DB collection: {collection_name}"] (41:14-41:84)
                  string_start [f"] (41:14-41:16)
                  string_content [Connected to YouTube API and Astra DB collection: ] (41:16-41:66)
                  interpolation [{collection_name}] (41:66-41:83)
                    { [{] (41:66-41:67)
                    identifier [collection_name] (41:67-41:82)
                    } [}] (41:82-41:83)
                  string_end ["] (41:83-41:84)
                ) [)] (41:84-41:85)
      function_definition [def create_vector(self, text):
        """Create normalized vector for text embedding."""
        vector = np.random.normal(0, 1, self.vector_dim)
        normalized_vector = vector / np.linalg.norm(vector)
        return normalized_vector.tolist()] (43:4-47:41)
        def [def] (43:4-43:7)
        identifier [create_vector] (43:8-43:21)
        parameters [(self, text)] (43:21-43:33)
          ( [(] (43:21-43:22)
          identifier [self] (43:22-43:26)
          , [,] (43:26-43:27)
          identifier [text] (43:28-43:32)
          ) [)] (43:32-43:33)
        : [:] (43:33-43:34)
        block ["""Create normalized vector for text embedding."""
        vector = np.random.normal(0, 1, self.vector_dim)
        normalized_vector = vector / np.linalg.norm(vector)
        return normalized_vector.tolist()] (44:8-47:41)
          expression_statement ["""Create normalized vector for text embedding."""] (44:8-44:58)
            string ["""Create normalized vector for text embedding."""] (44:8-44:58)
              string_start ["""] (44:8-44:11)
              string_content [Create normalized vector for text embedding.] (44:11-44:55)
              string_end ["""] (44:55-44:58)
          expression_statement [vector = np.random.normal(0, 1, self.vector_dim)] (45:8-45:56)
            assignment [vector = np.random.normal(0, 1, self.vector_dim)] (45:8-45:56)
              identifier [vector] (45:8-45:14)
              = [=] (45:15-45:16)
              call [np.random.normal(0, 1, self.vector_dim)] (45:17-45:56)
                attribute [np.random.normal] (45:17-45:33)
                  attribute [np.random] (45:17-45:26)
                    identifier [np] (45:17-45:19)
                    . [.] (45:19-45:20)
                    identifier [random] (45:20-45:26)
                  . [.] (45:26-45:27)
                  identifier [normal] (45:27-45:33)
                argument_list [(0, 1, self.vector_dim)] (45:33-45:56)
                  ( [(] (45:33-45:34)
                  integer [0] (45:34-45:35)
                  , [,] (45:35-45:36)
                  integer [1] (45:37-45:38)
                  , [,] (45:38-45:39)
                  attribute [self.vector_dim] (45:40-45:55)
                    identifier [self] (45:40-45:44)
                    . [.] (45:44-45:45)
                    identifier [vector_dim] (45:45-45:55)
                  ) [)] (45:55-45:56)
          expression_statement [normalized_vector = vector / np.linalg.norm(vector)] (46:8-46:59)
            assignment [normalized_vector = vector / np.linalg.norm(vector)] (46:8-46:59)
              identifier [normalized_vector] (46:8-46:25)
              = [=] (46:26-46:27)
              binary_operator [vector / np.linalg.norm(vector)] (46:28-46:59)
                identifier [vector] (46:28-46:34)
                / [/] (46:35-46:36)
                call [np.linalg.norm(vector)] (46:37-46:59)
                  attribute [np.linalg.norm] (46:37-46:51)
                    attribute [np.linalg] (46:37-46:46)
                      identifier [np] (46:37-46:39)
                      . [.] (46:39-46:40)
                      identifier [linalg] (46:40-46:46)
                    . [.] (46:46-46:47)
                    identifier [norm] (46:47-46:51)
                  argument_list [(vector)] (46:51-46:59)
                    ( [(] (46:51-46:52)
                    identifier [vector] (46:52-46:58)
                    ) [)] (46:58-46:59)
          return_statement [return normalized_vector.tolist()] (47:8-47:41)
            return [return] (47:8-47:14)
            call [normalized_vector.tolist()] (47:15-47:41)
              attribute [normalized_vector.tolist] (47:15-47:39)
                identifier [normalized_vector] (47:15-47:32)
                . [.] (47:32-47:33)
                identifier [tolist] (47:33-47:39)
              argument_list [()] (47:39-47:41)
                ( [(] (47:39-47:40)
                ) [)] (47:40-47:41)
      function_definition [def prepare_document(self, video_data):
        """Prepare video data for AstraDB storage."""
        try:
            # Create a simpler text content for vector creation
            title = video_data.get('title', '')[:1000]
            description = video_data.get('description', '')[:3000]

            comment_texts = []
            for comment in video_data.get('comments', [])[:5]:
                comment_text = comment.get('text', '')[:500]
                comment_texts.append(comment_text)

            text_content = f"{title} {description} {' '.join(comment_texts)}"

            content_bytes = text_content.encode('utf-8')
            if len(content_bytes) > 8000:
                content_bytes = content_bytes[:8000]
                text_content = content_bytes.decode('utf-8', errors='ignore')

            metadata = {
                'video_id': video_data.get('video_id', ''),
                'title': title,
                'channel_title': video_data.get('channel_title', '')[:100],
                'view_count': video_data.get('view_count', 0),
                'like_count': video_data.get('like_count', 0),
                'comment_count': video_data.get('comment_count', 0),
                'published_at': video_data.get('published_at', ''),
                'scraped_at': datetime.now().isoformat(),
                'comments': [{'text': t[:500], 'author': c.get('author', '')[:100]}
                             for t, c in zip(comment_texts, video_data.get('comments', [])[:5])]
            }

            document = {
                'content': text_content,
                'metadata': metadata,
                '$vector': self.create_vector(text_content)
            }

            return document
        except Exception as e:
            print(f"Error preparing document: {e}")
            return None] (49:4-90:23)
        def [def] (49:4-49:7)
        identifier [prepare_document] (49:8-49:24)
        parameters [(self, video_data)] (49:24-49:42)
          ( [(] (49:24-49:25)
          identifier [self] (49:25-49:29)
          , [,] (49:29-49:30)
          identifier [video_data] (49:31-49:41)
          ) [)] (49:41-49:42)
        : [:] (49:42-49:43)
        block ["""Prepare video data for AstraDB storage."""
        try:
            # Create a simpler text content for vector creation
            title = video_data.get('title', '')[:1000]
            description = video_data.get('description', '')[:3000]

            comment_texts = []
            for comment in video_data.get('comments', [])[:5]:
                comment_text = comment.get('text', '')[:500]
                comment_texts.append(comment_text)

            text_content = f"{title} {description} {' '.join(comment_texts)}"

            content_bytes = text_content.encode('utf-8')
            if len(content_bytes) > 8000:
                content_bytes = content_bytes[:8000]
                text_content = content_bytes.decode('utf-8', errors='ignore')

            metadata = {
                'video_id': video_data.get('video_id', ''),
                'title': title,
                'channel_title': video_data.get('channel_title', '')[:100],
                'view_count': video_data.get('view_count', 0),
                'like_count': video_data.get('like_count', 0),
                'comment_count': video_data.get('comment_count', 0),
                'published_at': video_data.get('published_at', ''),
                'scraped_at': datetime.now().isoformat(),
                'comments': [{'text': t[:500], 'author': c.get('author', '')[:100]}
                             for t, c in zip(comment_texts, video_data.get('comments', [])[:5])]
            }

            document = {
                'content': text_content,
                'metadata': metadata,
                '$vector': self.create_vector(text_content)
            }

            return document
        except Exception as e:
            print(f"Error preparing document: {e}")
            return None] (50:8-90:23)
          expression_statement ["""Prepare video data for AstraDB storage."""] (50:8-50:53)
            string ["""Prepare video data for AstraDB storage."""] (50:8-50:53)
              string_start ["""] (50:8-50:11)
              string_content [Prepare video data for AstraDB storage.] (50:11-50:50)
              string_end ["""] (50:50-50:53)
          try_statement [try:
            # Create a simpler text content for vector creation
            title = video_data.get('title', '')[:1000]
            description = video_data.get('description', '')[:3000]

            comment_texts = []
            for comment in video_data.get('comments', [])[:5]:
                comment_text = comment.get('text', '')[:500]
                comment_texts.append(comment_text)

            text_content = f"{title} {description} {' '.join(comment_texts)}"

            content_bytes = text_content.encode('utf-8')
            if len(content_bytes) > 8000:
                content_bytes = content_bytes[:8000]
                text_content = content_bytes.decode('utf-8', errors='ignore')

            metadata = {
                'video_id': video_data.get('video_id', ''),
                'title': title,
                'channel_title': video_data.get('channel_title', '')[:100],
                'view_count': video_data.get('view_count', 0),
                'like_count': video_data.get('like_count', 0),
                'comment_count': video_data.get('comment_count', 0),
                'published_at': video_data.get('published_at', ''),
                'scraped_at': datetime.now().isoformat(),
                'comments': [{'text': t[:500], 'author': c.get('author', '')[:100]}
                             for t, c in zip(comment_texts, video_data.get('comments', [])[:5])]
            }

            document = {
                'content': text_content,
                'metadata': metadata,
                '$vector': self.create_vector(text_content)
            }

            return document
        except Exception as e:
            print(f"Error preparing document: {e}")
            return None] (51:8-90:23)
            try [try] (51:8-51:11)
            : [:] (51:11-51:12)
            comment [# Create a simpler text content for vector creation] (52:12-52:63)
            block [title = video_data.get('title', '')[:1000]
            description = video_data.get('description', '')[:3000]

            comment_texts = []
            for comment in video_data.get('comments', [])[:5]:
                comment_text = comment.get('text', '')[:500]
                comment_texts.append(comment_text)

            text_content = f"{title} {description} {' '.join(comment_texts)}"

            content_bytes = text_content.encode('utf-8')
            if len(content_bytes) > 8000:
                content_bytes = content_bytes[:8000]
                text_content = content_bytes.decode('utf-8', errors='ignore')

            metadata = {
                'video_id': video_data.get('video_id', ''),
                'title': title,
                'channel_title': video_data.get('channel_title', '')[:100],
                'view_count': video_data.get('view_count', 0),
                'like_count': video_data.get('like_count', 0),
                'comment_count': video_data.get('comment_count', 0),
                'published_at': video_data.get('published_at', ''),
                'scraped_at': datetime.now().isoformat(),
                'comments': [{'text': t[:500], 'author': c.get('author', '')[:100]}
                             for t, c in zip(comment_texts, video_data.get('comments', [])[:5])]
            }

            document = {
                'content': text_content,
                'metadata': metadata,
                '$vector': self.create_vector(text_content)
            }

            return document] (53:12-87:27)
              expression_statement [title = video_data.get('title', '')[:1000]] (53:12-53:54)
                assignment [title = video_data.get('title', '')[:1000]] (53:12-53:54)
                  identifier [title] (53:12-53:17)
                  = [=] (53:18-53:19)
                  subscript [video_data.get('title', '')[:1000]] (53:20-53:54)
                    call [video_data.get('title', '')] (53:20-53:47)
                      attribute [video_data.get] (53:20-53:34)
                        identifier [video_data] (53:20-53:30)
                        . [.] (53:30-53:31)
                        identifier [get] (53:31-53:34)
                      argument_list [('title', '')] (53:34-53:47)
                        ( [(] (53:34-53:35)
                        string ['title'] (53:35-53:42)
                          string_start ['] (53:35-53:36)
                          string_content [title] (53:36-53:41)
                          string_end ['] (53:41-53:42)
                        , [,] (53:42-53:43)
                        string [''] (53:44-53:46)
                          string_start ['] (53:44-53:45)
                          string_end ['] (53:45-53:46)
                        ) [)] (53:46-53:47)
                    [ [[] (53:47-53:48)
                    slice [:1000] (53:48-53:53)
                      : [:] (53:48-53:49)
                      integer [1000] (53:49-53:53)
                    ] []] (53:53-53:54)
              expression_statement [description = video_data.get('description', '')[:3000]] (54:12-54:66)
                assignment [description = video_data.get('description', '')[:3000]] (54:12-54:66)
                  identifier [description] (54:12-54:23)
                  = [=] (54:24-54:25)
                  subscript [video_data.get('description', '')[:3000]] (54:26-54:66)
                    call [video_data.get('description', '')] (54:26-54:59)
                      attribute [video_data.get] (54:26-54:40)
                        identifier [video_data] (54:26-54:36)
                        . [.] (54:36-54:37)
                        identifier [get] (54:37-54:40)
                      argument_list [('description', '')] (54:40-54:59)
                        ( [(] (54:40-54:41)
                        string ['description'] (54:41-54:54)
                          string_start ['] (54:41-54:42)
                          string_content [description] (54:42-54:53)
                          string_end ['] (54:53-54:54)
                        , [,] (54:54-54:55)
                        string [''] (54:56-54:58)
                          string_start ['] (54:56-54:57)
                          string_end ['] (54:57-54:58)
                        ) [)] (54:58-54:59)
                    [ [[] (54:59-54:60)
                    slice [:3000] (54:60-54:65)
                      : [:] (54:60-54:61)
                      integer [3000] (54:61-54:65)
                    ] []] (54:65-54:66)
              expression_statement [comment_texts = []] (56:12-56:30)
                assignment [comment_texts = []] (56:12-56:30)
                  identifier [comment_texts] (56:12-56:25)
                  = [=] (56:26-56:27)
                  list [[]] (56:28-56:30)
                    [ [[] (56:28-56:29)
                    ] []] (56:29-56:30)
              for_statement [for comment in video_data.get('comments', [])[:5]:
                comment_text = comment.get('text', '')[:500]
                comment_texts.append(comment_text)] (57:12-59:50)
                for [for] (57:12-57:15)
                identifier [comment] (57:16-57:23)
                in [in] (57:24-57:26)
                subscript [video_data.get('comments', [])[:5]] (57:27-57:61)
                  call [video_data.get('comments', [])] (57:27-57:57)
                    attribute [video_data.get] (57:27-57:41)
                      identifier [video_data] (57:27-57:37)
                      . [.] (57:37-57:38)
                      identifier [get] (57:38-57:41)
                    argument_list [('comments', [])] (57:41-57:57)
                      ( [(] (57:41-57:42)
                      string ['comments'] (57:42-57:52)
                        string_start ['] (57:42-57:43)
                        string_content [comments] (57:43-57:51)
                        string_end ['] (57:51-57:52)
                      , [,] (57:52-57:53)
                      list [[]] (57:54-57:56)
                        [ [[] (57:54-57:55)
                        ] []] (57:55-57:56)
                      ) [)] (57:56-57:57)
                  [ [[] (57:57-57:58)
                  slice [:5] (57:58-57:60)
                    : [:] (57:58-57:59)
                    integer [5] (57:59-57:60)
                  ] []] (57:60-57:61)
                : [:] (57:61-57:62)
                block [comment_text = comment.get('text', '')[:500]
                comment_texts.append(comment_text)] (58:16-59:50)
                  expression_statement [comment_text = comment.get('text', '')[:500]] (58:16-58:60)
                    assignment [comment_text = comment.get('text', '')[:500]] (58:16-58:60)
                      identifier [comment_text] (58:16-58:28)
                      = [=] (58:29-58:30)
                      subscript [comment.get('text', '')[:500]] (58:31-58:60)
                        call [comment.get('text', '')] (58:31-58:54)
                          attribute [comment.get] (58:31-58:42)
                            identifier [comment] (58:31-58:38)
                            . [.] (58:38-58:39)
                            identifier [get] (58:39-58:42)
                          argument_list [('text', '')] (58:42-58:54)
                            ( [(] (58:42-58:43)
                            string ['text'] (58:43-58:49)
                              string_start ['] (58:43-58:44)
                              string_content [text] (58:44-58:48)
                              string_end ['] (58:48-58:49)
                            , [,] (58:49-58:50)
                            string [''] (58:51-58:53)
                              string_start ['] (58:51-58:52)
                              string_end ['] (58:52-58:53)
                            ) [)] (58:53-58:54)
                        [ [[] (58:54-58:55)
                        slice [:500] (58:55-58:59)
                          : [:] (58:55-58:56)
                          integer [500] (58:56-58:59)
                        ] []] (58:59-58:60)
                  expression_statement [comment_texts.append(comment_text)] (59:16-59:50)
                    call [comment_texts.append(comment_text)] (59:16-59:50)
                      attribute [comment_texts.append] (59:16-59:36)
                        identifier [comment_texts] (59:16-59:29)
                        . [.] (59:29-59:30)
                        identifier [append] (59:30-59:36)
                      argument_list [(comment_text)] (59:36-59:50)
                        ( [(] (59:36-59:37)
                        identifier [comment_text] (59:37-59:49)
                        ) [)] (59:49-59:50)
              expression_statement [text_content = f"{title} {description} {' '.join(comment_texts)}"] (61:12-61:77)
                assignment [text_content = f"{title} {description} {' '.join(comment_texts)}"] (61:12-61:77)
                  identifier [text_content] (61:12-61:24)
                  = [=] (61:25-61:26)
                  string [f"{title} {description} {' '.join(comment_texts)}"] (61:27-61:77)
                    string_start [f"] (61:27-61:29)
                    interpolation [{title}] (61:29-61:36)
                      { [{] (61:29-61:30)
                      identifier [title] (61:30-61:35)
                      } [}] (61:35-61:36)
                    string_content [ ] (61:36-61:37)
                    interpolation [{description}] (61:37-61:50)
                      { [{] (61:37-61:38)
                      identifier [description] (61:38-61:49)
                      } [}] (61:49-61:50)
                    string_content [ ] (61:50-61:51)
                    interpolation [{' '.join(comment_texts)}] (61:51-61:76)
                      { [{] (61:51-61:52)
                      call [' '.join(comment_texts)] (61:52-61:75)
                        attribute [' '.join] (61:52-61:60)
                          string [' '] (61:52-61:55)
                            string_start ['] (61:52-61:53)
                            string_content [ ] (61:53-61:54)
                            string_end ['] (61:54-61:55)
                          . [.] (61:55-61:56)
                          identifier [join] (61:56-61:60)
                        argument_list [(comment_texts)] (61:60-61:75)
                          ( [(] (61:60-61:61)
                          identifier [comment_texts] (61:61-61:74)
                          ) [)] (61:74-61:75)
                      } [}] (61:75-61:76)
                    string_end ["] (61:76-61:77)
              expression_statement [content_bytes = text_content.encode('utf-8')] (63:12-63:56)
                assignment [content_bytes = text_content.encode('utf-8')] (63:12-63:56)
                  identifier [content_bytes] (63:12-63:25)
                  = [=] (63:26-63:27)
                  call [text_content.encode('utf-8')] (63:28-63:56)
                    attribute [text_content.encode] (63:28-63:47)
                      identifier [text_content] (63:28-63:40)
                      . [.] (63:40-63:41)
                      identifier [encode] (63:41-63:47)
                    argument_list [('utf-8')] (63:47-63:56)
                      ( [(] (63:47-63:48)
                      string ['utf-8'] (63:48-63:55)
                        string_start ['] (63:48-63:49)
                        string_content [utf-8] (63:49-63:54)
                        string_end ['] (63:54-63:55)
                      ) [)] (63:55-63:56)
              if_statement [if len(content_bytes) > 8000:
                content_bytes = content_bytes[:8000]
                text_content = content_bytes.decode('utf-8', errors='ignore')] (64:12-66:77)
                if [if] (64:12-64:14)
                comparison_operator [len(content_bytes) > 8000] (64:15-64:40)
                  call [len(content_bytes)] (64:15-64:33)
                    identifier [len] (64:15-64:18)
                    argument_list [(content_bytes)] (64:18-64:33)
                      ( [(] (64:18-64:19)
                      identifier [content_bytes] (64:19-64:32)
                      ) [)] (64:32-64:33)
                  > [>] (64:34-64:35)
                  integer [8000] (64:36-64:40)
                : [:] (64:40-64:41)
                block [content_bytes = content_bytes[:8000]
                text_content = content_bytes.decode('utf-8', errors='ignore')] (65:16-66:77)
                  expression_statement [content_bytes = content_bytes[:8000]] (65:16-65:52)
                    assignment [content_bytes = content_bytes[:8000]] (65:16-65:52)
                      identifier [content_bytes] (65:16-65:29)
                      = [=] (65:30-65:31)
                      subscript [content_bytes[:8000]] (65:32-65:52)
                        identifier [content_bytes] (65:32-65:45)
                        [ [[] (65:45-65:46)
                        slice [:8000] (65:46-65:51)
                          : [:] (65:46-65:47)
                          integer [8000] (65:47-65:51)
                        ] []] (65:51-65:52)
                  expression_statement [text_content = content_bytes.decode('utf-8', errors='ignore')] (66:16-66:77)
                    assignment [text_content = content_bytes.decode('utf-8', errors='ignore')] (66:16-66:77)
                      identifier [text_content] (66:16-66:28)
                      = [=] (66:29-66:30)
                      call [content_bytes.decode('utf-8', errors='ignore')] (66:31-66:77)
                        attribute [content_bytes.decode] (66:31-66:51)
                          identifier [content_bytes] (66:31-66:44)
                          . [.] (66:44-66:45)
                          identifier [decode] (66:45-66:51)
                        argument_list [('utf-8', errors='ignore')] (66:51-66:77)
                          ( [(] (66:51-66:52)
                          string ['utf-8'] (66:52-66:59)
                            string_start ['] (66:52-66:53)
                            string_content [utf-8] (66:53-66:58)
                            string_end ['] (66:58-66:59)
                          , [,] (66:59-66:60)
                          keyword_argument [errors='ignore'] (66:61-66:76)
                            identifier [errors] (66:61-66:67)
                            = [=] (66:67-66:68)
                            string ['ignore'] (66:68-66:76)
                              string_start ['] (66:68-66:69)
                              string_content [ignore] (66:69-66:75)
                              string_end ['] (66:75-66:76)
                          ) [)] (66:76-66:77)
              expression_statement [metadata = {
                'video_id': video_data.get('video_id', ''),
                'title': title,
                'channel_title': video_data.get('channel_title', '')[:100],
                'view_count': video_data.get('view_count', 0),
                'like_count': video_data.get('like_count', 0),
                'comment_count': video_data.get('comment_count', 0),
                'published_at': video_data.get('published_at', ''),
                'scraped_at': datetime.now().isoformat(),
                'comments': [{'text': t[:500], 'author': c.get('author', '')[:100]}
                             for t, c in zip(comment_texts, video_data.get('comments', [])[:5])]
            }] (68:12-79:13)
                assignment [metadata = {
                'video_id': video_data.get('video_id', ''),
                'title': title,
                'channel_title': video_data.get('channel_title', '')[:100],
                'view_count': video_data.get('view_count', 0),
                'like_count': video_data.get('like_count', 0),
                'comment_count': video_data.get('comment_count', 0),
                'published_at': video_data.get('published_at', ''),
                'scraped_at': datetime.now().isoformat(),
                'comments': [{'text': t[:500], 'author': c.get('author', '')[:100]}
                             for t, c in zip(comment_texts, video_data.get('comments', [])[:5])]
            }] (68:12-79:13)
                  identifier [metadata] (68:12-68:20)
                  = [=] (68:21-68:22)
                  dictionary [{
                'video_id': video_data.get('video_id', ''),
                'title': title,
                'channel_title': video_data.get('channel_title', '')[:100],
                'view_count': video_data.get('view_count', 0),
                'like_count': video_data.get('like_count', 0),
                'comment_count': video_data.get('comment_count', 0),
                'published_at': video_data.get('published_at', ''),
                'scraped_at': datetime.now().isoformat(),
                'comments': [{'text': t[:500], 'author': c.get('author', '')[:100]}
                             for t, c in zip(comment_texts, video_data.get('comments', [])[:5])]
            }] (68:23-79:13)
                    { [{] (68:23-68:24)
                    pair ['video_id': video_data.get('video_id', '')] (69:16-69:58)
                      string ['video_id'] (69:16-69:26)
                        string_start ['] (69:16-69:17)
                        string_content [video_id] (69:17-69:25)
                        string_end ['] (69:25-69:26)
                      : [:] (69:26-69:27)
                      call [video_data.get('video_id', '')] (69:28-69:58)
                        attribute [video_data.get] (69:28-69:42)
                          identifier [video_data] (69:28-69:38)
                          . [.] (69:38-69:39)
                          identifier [get] (69:39-69:42)
                        argument_list [('video_id', '')] (69:42-69:58)
                          ( [(] (69:42-69:43)
                          string ['video_id'] (69:43-69:53)
                            string_start ['] (69:43-69:44)
                            string_content [video_id] (69:44-69:52)
                            string_end ['] (69:52-69:53)
                          , [,] (69:53-69:54)
                          string [''] (69:55-69:57)
                            string_start ['] (69:55-69:56)
                            string_end ['] (69:56-69:57)
                          ) [)] (69:57-69:58)
                    , [,] (69:58-69:59)
                    pair ['title': title] (70:16-70:30)
                      string ['title'] (70:16-70:23)
                        string_start ['] (70:16-70:17)
                        string_content [title] (70:17-70:22)
                        string_end ['] (70:22-70:23)
                      : [:] (70:23-70:24)
                      identifier [title] (70:25-70:30)
                    , [,] (70:30-70:31)
                    pair ['channel_title': video_data.get('channel_title', '')[:100]] (71:16-71:74)
                      string ['channel_title'] (71:16-71:31)
                        string_start ['] (71:16-71:17)
                        string_content [channel_title] (71:17-71:30)
                        string_end ['] (71:30-71:31)
                      : [:] (71:31-71:32)
                      subscript [video_data.get('channel_title', '')[:100]] (71:33-71:74)
                        call [video_data.get('channel_title', '')] (71:33-71:68)
                          attribute [video_data.get] (71:33-71:47)
                            identifier [video_data] (71:33-71:43)
                            . [.] (71:43-71:44)
                            identifier [get] (71:44-71:47)
                          argument_list [('channel_title', '')] (71:47-71:68)
                            ( [(] (71:47-71:48)
                            string ['channel_title'] (71:48-71:63)
                              string_start ['] (71:48-71:49)
                              string_content [channel_title] (71:49-71:62)
                              string_end ['] (71:62-71:63)
                            , [,] (71:63-71:64)
                            string [''] (71:65-71:67)
                              string_start ['] (71:65-71:66)
                              string_end ['] (71:66-71:67)
                            ) [)] (71:67-71:68)
                        [ [[] (71:68-71:69)
                        slice [:100] (71:69-71:73)
                          : [:] (71:69-71:70)
                          integer [100] (71:70-71:73)
                        ] []] (71:73-71:74)
                    , [,] (71:74-71:75)
                    pair ['view_count': video_data.get('view_count', 0)] (72:16-72:61)
                      string ['view_count'] (72:16-72:28)
                        string_start ['] (72:16-72:17)
                        string_content [view_count] (72:17-72:27)
                        string_end ['] (72:27-72:28)
                      : [:] (72:28-72:29)
                      call [video_data.get('view_count', 0)] (72:30-72:61)
                        attribute [video_data.get] (72:30-72:44)
                          identifier [video_data] (72:30-72:40)
                          . [.] (72:40-72:41)
                          identifier [get] (72:41-72:44)
                        argument_list [('view_count', 0)] (72:44-72:61)
                          ( [(] (72:44-72:45)
                          string ['view_count'] (72:45-72:57)
                            string_start ['] (72:45-72:46)
                            string_content [view_count] (72:46-72:56)
                            string_end ['] (72:56-72:57)
                          , [,] (72:57-72:58)
                          integer [0] (72:59-72:60)
                          ) [)] (72:60-72:61)
                    , [,] (72:61-72:62)
                    pair ['like_count': video_data.get('like_count', 0)] (73:16-73:61)
                      string ['like_count'] (73:16-73:28)
                        string_start ['] (73:16-73:17)
                        string_content [like_count] (73:17-73:27)
                        string_end ['] (73:27-73:28)
                      : [:] (73:28-73:29)
                      call [video_data.get('like_count', 0)] (73:30-73:61)
                        attribute [video_data.get] (73:30-73:44)
                          identifier [video_data] (73:30-73:40)
                          . [.] (73:40-73:41)
                          identifier [get] (73:41-73:44)
                        argument_list [('like_count', 0)] (73:44-73:61)
                          ( [(] (73:44-73:45)
                          string ['like_count'] (73:45-73:57)
                            string_start ['] (73:45-73:46)
                            string_content [like_count] (73:46-73:56)
                            string_end ['] (73:56-73:57)
                          , [,] (73:57-73:58)
                          integer [0] (73:59-73:60)
                          ) [)] (73:60-73:61)
                    , [,] (73:61-73:62)
                    pair ['comment_count': video_data.get('comment_count', 0)] (74:16-74:67)
                      string ['comment_count'] (74:16-74:31)
                        string_start ['] (74:16-74:17)
                        string_content [comment_count] (74:17-74:30)
                        string_end ['] (74:30-74:31)
                      : [:] (74:31-74:32)
                      call [video_data.get('comment_count', 0)] (74:33-74:67)
                        attribute [video_data.get] (74:33-74:47)
                          identifier [video_data] (74:33-74:43)
                          . [.] (74:43-74:44)
                          identifier [get] (74:44-74:47)
                        argument_list [('comment_count', 0)] (74:47-74:67)
                          ( [(] (74:47-74:48)
                          string ['comment_count'] (74:48-74:63)
                            string_start ['] (74:48-74:49)
                            string_content [comment_count] (74:49-74:62)
                            string_end ['] (74:62-74:63)
                          , [,] (74:63-74:64)
                          integer [0] (74:65-74:66)
                          ) [)] (74:66-74:67)
                    , [,] (74:67-74:68)
                    pair ['published_at': video_data.get('published_at', '')] (75:16-75:66)
                      string ['published_at'] (75:16-75:30)
                        string_start ['] (75:16-75:17)
                        string_content [published_at] (75:17-75:29)
                        string_end ['] (75:29-75:30)
                      : [:] (75:30-75:31)
                      call [video_data.get('published_at', '')] (75:32-75:66)
                        attribute [video_data.get] (75:32-75:46)
                          identifier [video_data] (75:32-75:42)
                          . [.] (75:42-75:43)
                          identifier [get] (75:43-75:46)
                        argument_list [('published_at', '')] (75:46-75:66)
                          ( [(] (75:46-75:47)
                          string ['published_at'] (75:47-75:61)
                            string_start ['] (75:47-75:48)
                            string_content [published_at] (75:48-75:60)
                            string_end ['] (75:60-75:61)
                          , [,] (75:61-75:62)
                          string [''] (75:63-75:65)
                            string_start ['] (75:63-75:64)
                            string_end ['] (75:64-75:65)
                          ) [)] (75:65-75:66)
                    , [,] (75:66-75:67)
                    pair ['scraped_at': datetime.now().isoformat()] (76:16-76:56)
                      string ['scraped_at'] (76:16-76:28)
                        string_start ['] (76:16-76:17)
                        string_content [scraped_at] (76:17-76:27)
                        string_end ['] (76:27-76:28)
                      : [:] (76:28-76:29)
                      call [datetime.now().isoformat()] (76:30-76:56)
                        attribute [datetime.now().isoformat] (76:30-76:54)
                          call [datetime.now()] (76:30-76:44)
                            attribute [datetime.now] (76:30-76:42)
                              identifier [datetime] (76:30-76:38)
                              . [.] (76:38-76:39)
                              identifier [now] (76:39-76:42)
                            argument_list [()] (76:42-76:44)
                              ( [(] (76:42-76:43)
                              ) [)] (76:43-76:44)
                          . [.] (76:44-76:45)
                          identifier [isoformat] (76:45-76:54)
                        argument_list [()] (76:54-76:56)
                          ( [(] (76:54-76:55)
                          ) [)] (76:55-76:56)
                    , [,] (76:56-76:57)
                    pair ['comments': [{'text': t[:500], 'author': c.get('author', '')[:100]}
                             for t, c in zip(comment_texts, video_data.get('comments', [])[:5])]] (77:16-78:96)
                      string ['comments'] (77:16-77:26)
                        string_start ['] (77:16-77:17)
                        string_content [comments] (77:17-77:25)
                        string_end ['] (77:25-77:26)
                      : [:] (77:26-77:27)
                      list_comprehension [[{'text': t[:500], 'author': c.get('author', '')[:100]}
                             for t, c in zip(comment_texts, video_data.get('comments', [])[:5])]] (77:28-78:96)
                        [ [[] (77:28-77:29)
                        dictionary [{'text': t[:500], 'author': c.get('author', '')[:100]}] (77:29-77:83)
                          { [{] (77:29-77:30)
                          pair ['text': t[:500]] (77:30-77:45)
                            string ['text'] (77:30-77:36)
                              string_start ['] (77:30-77:31)
                              string_content [text] (77:31-77:35)
                              string_end ['] (77:35-77:36)
                            : [:] (77:36-77:37)
                            subscript [t[:500]] (77:38-77:45)
                              identifier [t] (77:38-77:39)
                              [ [[] (77:39-77:40)
                              slice [:500] (77:40-77:44)
                                : [:] (77:40-77:41)
                                integer [500] (77:41-77:44)
                              ] []] (77:44-77:45)
                          , [,] (77:45-77:46)
                          pair ['author': c.get('author', '')[:100]] (77:47-77:82)
                            string ['author'] (77:47-77:55)
                              string_start ['] (77:47-77:48)
                              string_content [author] (77:48-77:54)
                              string_end ['] (77:54-77:55)
                            : [:] (77:55-77:56)
                            subscript [c.get('author', '')[:100]] (77:57-77:82)
                              call [c.get('author', '')] (77:57-77:76)
                                attribute [c.get] (77:57-77:62)
                                  identifier [c] (77:57-77:58)
                                  . [.] (77:58-77:59)
                                  identifier [get] (77:59-77:62)
                                argument_list [('author', '')] (77:62-77:76)
                                  ( [(] (77:62-77:63)
                                  string ['author'] (77:63-77:71)
                                    string_start ['] (77:63-77:64)
                                    string_content [author] (77:64-77:70)
                                    string_end ['] (77:70-77:71)
                                  , [,] (77:71-77:72)
                                  string [''] (77:73-77:75)
                                    string_start ['] (77:73-77:74)
                                    string_end ['] (77:74-77:75)
                                  ) [)] (77:75-77:76)
                              [ [[] (77:76-77:77)
                              slice [:100] (77:77-77:81)
                                : [:] (77:77-77:78)
                                integer [100] (77:78-77:81)
                              ] []] (77:81-77:82)
                          } [}] (77:82-77:83)
                        for_in_clause [for t, c in zip(comment_texts, video_data.get('comments', [])[:5])] (78:29-78:95)
                          for [for] (78:29-78:32)
                          pattern_list [t, c] (78:33-78:37)
                            identifier [t] (78:33-78:34)
                            , [,] (78:34-78:35)
                            identifier [c] (78:36-78:37)
                          in [in] (78:38-78:40)
                          call [zip(comment_texts, video_data.get('comments', [])[:5])] (78:41-78:95)
                            identifier [zip] (78:41-78:44)
                            argument_list [(comment_texts, video_data.get('comments', [])[:5])] (78:44-78:95)
                              ( [(] (78:44-78:45)
                              identifier [comment_texts] (78:45-78:58)
                              , [,] (78:58-78:59)
                              subscript [video_data.get('comments', [])[:5]] (78:60-78:94)
                                call [video_data.get('comments', [])] (78:60-78:90)
                                  attribute [video_data.get] (78:60-78:74)
                                    identifier [video_data] (78:60-78:70)
                                    . [.] (78:70-78:71)
                                    identifier [get] (78:71-78:74)
                                  argument_list [('comments', [])] (78:74-78:90)
                                    ( [(] (78:74-78:75)
                                    string ['comments'] (78:75-78:85)
                                      string_start ['] (78:75-78:76)
                                      string_content [comments] (78:76-78:84)
                                      string_end ['] (78:84-78:85)
                                    , [,] (78:85-78:86)
                                    list [[]] (78:87-78:89)
                                      [ [[] (78:87-78:88)
                                      ] []] (78:88-78:89)
                                    ) [)] (78:89-78:90)
                                [ [[] (78:90-78:91)
                                slice [:5] (78:91-78:93)
                                  : [:] (78:91-78:92)
                                  integer [5] (78:92-78:93)
                                ] []] (78:93-78:94)
                              ) [)] (78:94-78:95)
                        ] []] (78:95-78:96)
                    } [}] (79:12-79:13)
              expression_statement [document = {
                'content': text_content,
                'metadata': metadata,
                '$vector': self.create_vector(text_content)
            }] (81:12-85:13)
                assignment [document = {
                'content': text_content,
                'metadata': metadata,
                '$vector': self.create_vector(text_content)
            }] (81:12-85:13)
                  identifier [document] (81:12-81:20)
                  = [=] (81:21-81:22)
                  dictionary [{
                'content': text_content,
                'metadata': metadata,
                '$vector': self.create_vector(text_content)
            }] (81:23-85:13)
                    { [{] (81:23-81:24)
                    pair ['content': text_content] (82:16-82:39)
                      string ['content'] (82:16-82:25)
                        string_start ['] (82:16-82:17)
                        string_content [content] (82:17-82:24)
                        string_end ['] (82:24-82:25)
                      : [:] (82:25-82:26)
                      identifier [text_content] (82:27-82:39)
                    , [,] (82:39-82:40)
                    pair ['metadata': metadata] (83:16-83:36)
                      string ['metadata'] (83:16-83:26)
                        string_start ['] (83:16-83:17)
                        string_content [metadata] (83:17-83:25)
                        string_end ['] (83:25-83:26)
                      : [:] (83:26-83:27)
                      identifier [metadata] (83:28-83:36)
                    , [,] (83:36-83:37)
                    pair ['$vector': self.create_vector(text_content)] (84:16-84:59)
                      string ['$vector'] (84:16-84:25)
                        string_start ['] (84:16-84:17)
                        string_content [$vector] (84:17-84:24)
                        string_end ['] (84:24-84:25)
                      : [:] (84:25-84:26)
                      call [self.create_vector(text_content)] (84:27-84:59)
                        attribute [self.create_vector] (84:27-84:45)
                          identifier [self] (84:27-84:31)
                          . [.] (84:31-84:32)
                          identifier [create_vector] (84:32-84:45)
                        argument_list [(text_content)] (84:45-84:59)
                          ( [(] (84:45-84:46)
                          identifier [text_content] (84:46-84:58)
                          ) [)] (84:58-84:59)
                    } [}] (85:12-85:13)
              return_statement [return document] (87:12-87:27)
                return [return] (87:12-87:18)
                identifier [document] (87:19-87:27)
            except_clause [except Exception as e:
            print(f"Error preparing document: {e}")
            return None] (88:8-90:23)
              except [except] (88:8-88:14)
              as_pattern [Exception as e] (88:15-88:29)
                identifier [Exception] (88:15-88:24)
                as [as] (88:25-88:27)
                as_pattern_target [e] (88:28-88:29)
                  identifier [e] (88:28-88:29)
              : [:] (88:29-88:30)
              block [print(f"Error preparing document: {e}")
            return None] (89:12-90:23)
                expression_statement [print(f"Error preparing document: {e}")] (89:12-89:51)
                  call [print(f"Error preparing document: {e}")] (89:12-89:51)
                    identifier [print] (89:12-89:17)
                    argument_list [(f"Error preparing document: {e}")] (89:17-89:51)
                      ( [(] (89:17-89:18)
                      string [f"Error preparing document: {e}"] (89:18-89:50)
                        string_start [f"] (89:18-89:20)
                        string_content [Error preparing document: ] (89:20-89:46)
                        interpolation [{e}] (89:46-89:49)
                          { [{] (89:46-89:47)
                          identifier [e] (89:47-89:48)
                          } [}] (89:48-89:49)
                        string_end ["] (89:49-89:50)
                      ) [)] (89:50-89:51)
                return_statement [return None] (90:12-90:23)
                  return [return] (90:12-90:18)
                  none [None] (90:19-90:23)
      function_definition [def get_video_comments(self, video_id, max_comments=50):
        """Get comments for a video."""
        comments = []
        try:
            request = self.youtube.commentThreads().list(
                part="snippet",
                videoId=video_id,
                maxResults=min(max_comments, 100)
            )

            while request and len(comments) < max_comments:
                response = request.execute()

                for item in response['items']:
                    comment = item['snippet']['topLevelComment']['snippet']
                    comment_data = {
                        'author': comment['authorDisplayName'],
                        'text': comment['textDisplay'],
                        'like_count': comment['likeCount'],
                        'published_at': comment['publishedAt']
                    }
                    comments.append(comment_data)

                request = self.youtube.commentThreads().list_next(request, response)

        except Exception as e:
            print(f"Error fetching comments: {e}")

        return comments] (92:4-120:23)
        def [def] (92:4-92:7)
        identifier [get_video_comments] (92:8-92:26)
        parameters [(self, video_id, max_comments=50)] (92:26-92:59)
          ( [(] (92:26-92:27)
          identifier [self] (92:27-92:31)
          , [,] (92:31-92:32)
          identifier [video_id] (92:33-92:41)
          , [,] (92:41-92:42)
          default_parameter [max_comments=50] (92:43-92:58)
            identifier [max_comments] (92:43-92:55)
            = [=] (92:55-92:56)
            integer [50] (92:56-92:58)
          ) [)] (92:58-92:59)
        : [:] (92:59-92:60)
        block ["""Get comments for a video."""
        comments = []
        try:
            request = self.youtube.commentThreads().list(
                part="snippet",
                videoId=video_id,
                maxResults=min(max_comments, 100)
            )

            while request and len(comments) < max_comments:
                response = request.execute()

                for item in response['items']:
                    comment = item['snippet']['topLevelComment']['snippet']
                    comment_data = {
                        'author': comment['authorDisplayName'],
                        'text': comment['textDisplay'],
                        'like_count': comment['likeCount'],
                        'published_at': comment['publishedAt']
                    }
                    comments.append(comment_data)

                request = self.youtube.commentThreads().list_next(request, response)

        except Exception as e:
            print(f"Error fetching comments: {e}")

        return comments] (93:8-120:23)
          expression_statement ["""Get comments for a video."""] (93:8-93:39)
            string ["""Get comments for a video."""] (93:8-93:39)
              string_start ["""] (93:8-93:11)
              string_content [Get comments for a video.] (93:11-93:36)
              string_end ["""] (93:36-93:39)
          expression_statement [comments = []] (94:8-94:21)
            assignment [comments = []] (94:8-94:21)
              identifier [comments] (94:8-94:16)
              = [=] (94:17-94:18)
              list [[]] (94:19-94:21)
                [ [[] (94:19-94:20)
                ] []] (94:20-94:21)
          try_statement [try:
            request = self.youtube.commentThreads().list(
                part="snippet",
                videoId=video_id,
                maxResults=min(max_comments, 100)
            )

            while request and len(comments) < max_comments:
                response = request.execute()

                for item in response['items']:
                    comment = item['snippet']['topLevelComment']['snippet']
                    comment_data = {
                        'author': comment['authorDisplayName'],
                        'text': comment['textDisplay'],
                        'like_count': comment['likeCount'],
                        'published_at': comment['publishedAt']
                    }
                    comments.append(comment_data)

                request = self.youtube.commentThreads().list_next(request, response)

        except Exception as e:
            print(f"Error fetching comments: {e}")] (95:8-118:50)
            try [try] (95:8-95:11)
            : [:] (95:11-95:12)
            block [request = self.youtube.commentThreads().list(
                part="snippet",
                videoId=video_id,
                maxResults=min(max_comments, 100)
            )

            while request and len(comments) < max_comments:
                response = request.execute()

                for item in response['items']:
                    comment = item['snippet']['topLevelComment']['snippet']
                    comment_data = {
                        'author': comment['authorDisplayName'],
                        'text': comment['textDisplay'],
                        'like_count': comment['likeCount'],
                        'published_at': comment['publishedAt']
                    }
                    comments.append(comment_data)

                request = self.youtube.commentThreads().list_next(request, response)] (96:12-115:84)
              expression_statement [request = self.youtube.commentThreads().list(
                part="snippet",
                videoId=video_id,
                maxResults=min(max_comments, 100)
            )] (96:12-100:13)
                assignment [request = self.youtube.commentThreads().list(
                part="snippet",
                videoId=video_id,
                maxResults=min(max_comments, 100)
            )] (96:12-100:13)
                  identifier [request] (96:12-96:19)
                  = [=] (96:20-96:21)
                  call [self.youtube.commentThreads().list(
                part="snippet",
                videoId=video_id,
                maxResults=min(max_comments, 100)
            )] (96:22-100:13)
                    attribute [self.youtube.commentThreads().list] (96:22-96:56)
                      call [self.youtube.commentThreads()] (96:22-96:51)
                        attribute [self.youtube.commentThreads] (96:22-96:49)
                          attribute [self.youtube] (96:22-96:34)
                            identifier [self] (96:22-96:26)
                            . [.] (96:26-96:27)
                            identifier [youtube] (96:27-96:34)
                          . [.] (96:34-96:35)
                          identifier [commentThreads] (96:35-96:49)
                        argument_list [()] (96:49-96:51)
                          ( [(] (96:49-96:50)
                          ) [)] (96:50-96:51)
                      . [.] (96:51-96:52)
                      identifier [list] (96:52-96:56)
                    argument_list [(
                part="snippet",
                videoId=video_id,
                maxResults=min(max_comments, 100)
            )] (96:56-100:13)
                      ( [(] (96:56-96:57)
                      keyword_argument [part="snippet"] (97:16-97:30)
                        identifier [part] (97:16-97:20)
                        = [=] (97:20-97:21)
                        string ["snippet"] (97:21-97:30)
                          string_start ["] (97:21-97:22)
                          string_content [snippet] (97:22-97:29)
                          string_end ["] (97:29-97:30)
                      , [,] (97:30-97:31)
                      keyword_argument [videoId=video_id] (98:16-98:32)
                        identifier [videoId] (98:16-98:23)
                        = [=] (98:23-98:24)
                        identifier [video_id] (98:24-98:32)
                      , [,] (98:32-98:33)
                      keyword_argument [maxResults=min(max_comments, 100)] (99:16-99:49)
                        identifier [maxResults] (99:16-99:26)
                        = [=] (99:26-99:27)
                        call [min(max_comments, 100)] (99:27-99:49)
                          identifier [min] (99:27-99:30)
                          argument_list [(max_comments, 100)] (99:30-99:49)
                            ( [(] (99:30-99:31)
                            identifier [max_comments] (99:31-99:43)
                            , [,] (99:43-99:44)
                            integer [100] (99:45-99:48)
                            ) [)] (99:48-99:49)
                      ) [)] (100:12-100:13)
              while_statement [while request and len(comments) < max_comments:
                response = request.execute()

                for item in response['items']:
                    comment = item['snippet']['topLevelComment']['snippet']
                    comment_data = {
                        'author': comment['authorDisplayName'],
                        'text': comment['textDisplay'],
                        'like_count': comment['likeCount'],
                        'published_at': comment['publishedAt']
                    }
                    comments.append(comment_data)

                request = self.youtube.commentThreads().list_next(request, response)] (102:12-115:84)
                while [while] (102:12-102:17)
                boolean_operator [request and len(comments) < max_comments] (102:18-102:58)
                  identifier [request] (102:18-102:25)
                  and [and] (102:26-102:29)
                  comparison_operator [len(comments) < max_comments] (102:30-102:58)
                    call [len(comments)] (102:30-102:43)
                      identifier [len] (102:30-102:33)
                      argument_list [(comments)] (102:33-102:43)
                        ( [(] (102:33-102:34)
                        identifier [comments] (102:34-102:42)
                        ) [)] (102:42-102:43)
                    < [<] (102:44-102:45)
                    identifier [max_comments] (102:46-102:58)
                : [:] (102:58-102:59)
                block [response = request.execute()

                for item in response['items']:
                    comment = item['snippet']['topLevelComment']['snippet']
                    comment_data = {
                        'author': comment['authorDisplayName'],
                        'text': comment['textDisplay'],
                        'like_count': comment['likeCount'],
                        'published_at': comment['publishedAt']
                    }
                    comments.append(comment_data)

                request = self.youtube.commentThreads().list_next(request, response)] (103:16-115:84)
                  expression_statement [response = request.execute()] (103:16-103:44)
                    assignment [response = request.execute()] (103:16-103:44)
                      identifier [response] (103:16-103:24)
                      = [=] (103:25-103:26)
                      call [request.execute()] (103:27-103:44)
                        attribute [request.execute] (103:27-103:42)
                          identifier [request] (103:27-103:34)
                          . [.] (103:34-103:35)
                          identifier [execute] (103:35-103:42)
                        argument_list [()] (103:42-103:44)
                          ( [(] (103:42-103:43)
                          ) [)] (103:43-103:44)
                  for_statement [for item in response['items']:
                    comment = item['snippet']['topLevelComment']['snippet']
                    comment_data = {
                        'author': comment['authorDisplayName'],
                        'text': comment['textDisplay'],
                        'like_count': comment['likeCount'],
                        'published_at': comment['publishedAt']
                    }
                    comments.append(comment_data)] (105:16-113:49)
                    for [for] (105:16-105:19)
                    identifier [item] (105:20-105:24)
                    in [in] (105:25-105:27)
                    subscript [response['items']] (105:28-105:45)
                      identifier [response] (105:28-105:36)
                      [ [[] (105:36-105:37)
                      string ['items'] (105:37-105:44)
                        string_start ['] (105:37-105:38)
                        string_content [items] (105:38-105:43)
                        string_end ['] (105:43-105:44)
                      ] []] (105:44-105:45)
                    : [:] (105:45-105:46)
                    block [comment = item['snippet']['topLevelComment']['snippet']
                    comment_data = {
                        'author': comment['authorDisplayName'],
                        'text': comment['textDisplay'],
                        'like_count': comment['likeCount'],
                        'published_at': comment['publishedAt']
                    }
                    comments.append(comment_data)] (106:20-113:49)
                      expression_statement [comment = item['snippet']['topLevelComment']['snippet']] (106:20-106:75)
                        assignment [comment = item['snippet']['topLevelComment']['snippet']] (106:20-106:75)
                          identifier [comment] (106:20-106:27)
                          = [=] (106:28-106:29)
                          subscript [item['snippet']['topLevelComment']['snippet']] (106:30-106:75)
                            subscript [item['snippet']['topLevelComment']] (106:30-106:64)
                              subscript [item['snippet']] (106:30-106:45)
                                identifier [item] (106:30-106:34)
                                [ [[] (106:34-106:35)
                                string ['snippet'] (106:35-106:44)
                                  string_start ['] (106:35-106:36)
                                  string_content [snippet] (106:36-106:43)
                                  string_end ['] (106:43-106:44)
                                ] []] (106:44-106:45)
                              [ [[] (106:45-106:46)
                              string ['topLevelComment'] (106:46-106:63)
                                string_start ['] (106:46-106:47)
                                string_content [topLevelComment] (106:47-106:62)
                                string_end ['] (106:62-106:63)
                              ] []] (106:63-106:64)
                            [ [[] (106:64-106:65)
                            string ['snippet'] (106:65-106:74)
                              string_start ['] (106:65-106:66)
                              string_content [snippet] (106:66-106:73)
                              string_end ['] (106:73-106:74)
                            ] []] (106:74-106:75)
                      expression_statement [comment_data = {
                        'author': comment['authorDisplayName'],
                        'text': comment['textDisplay'],
                        'like_count': comment['likeCount'],
                        'published_at': comment['publishedAt']
                    }] (107:20-112:21)
                        assignment [comment_data = {
                        'author': comment['authorDisplayName'],
                        'text': comment['textDisplay'],
                        'like_count': comment['likeCount'],
                        'published_at': comment['publishedAt']
                    }] (107:20-112:21)
                          identifier [comment_data] (107:20-107:32)
                          = [=] (107:33-107:34)
                          dictionary [{
                        'author': comment['authorDisplayName'],
                        'text': comment['textDisplay'],
                        'like_count': comment['likeCount'],
                        'published_at': comment['publishedAt']
                    }] (107:35-112:21)
                            { [{] (107:35-107:36)
                            pair ['author': comment['authorDisplayName']] (108:24-108:62)
                              string ['author'] (108:24-108:32)
                                string_start ['] (108:24-108:25)
                                string_content [author] (108:25-108:31)
                                string_end ['] (108:31-108:32)
                              : [:] (108:32-108:33)
                              subscript [comment['authorDisplayName']] (108:34-108:62)
                                identifier [comment] (108:34-108:41)
                                [ [[] (108:41-108:42)
                                string ['authorDisplayName'] (108:42-108:61)
                                  string_start ['] (108:42-108:43)
                                  string_content [authorDisplayName] (108:43-108:60)
                                  string_end ['] (108:60-108:61)
                                ] []] (108:61-108:62)
                            , [,] (108:62-108:63)
                            pair ['text': comment['textDisplay']] (109:24-109:54)
                              string ['text'] (109:24-109:30)
                                string_start ['] (109:24-109:25)
                                string_content [text] (109:25-109:29)
                                string_end ['] (109:29-109:30)
                              : [:] (109:30-109:31)
                              subscript [comment['textDisplay']] (109:32-109:54)
                                identifier [comment] (109:32-109:39)
                                [ [[] (109:39-109:40)
                                string ['textDisplay'] (109:40-109:53)
                                  string_start ['] (109:40-109:41)
                                  string_content [textDisplay] (109:41-109:52)
                                  string_end ['] (109:52-109:53)
                                ] []] (109:53-109:54)
                            , [,] (109:54-109:55)
                            pair ['like_count': comment['likeCount']] (110:24-110:58)
                              string ['like_count'] (110:24-110:36)
                                string_start ['] (110:24-110:25)
                                string_content [like_count] (110:25-110:35)
                                string_end ['] (110:35-110:36)
                              : [:] (110:36-110:37)
                              subscript [comment['likeCount']] (110:38-110:58)
                                identifier [comment] (110:38-110:45)
                                [ [[] (110:45-110:46)
                                string ['likeCount'] (110:46-110:57)
                                  string_start ['] (110:46-110:47)
                                  string_content [likeCount] (110:47-110:56)
                                  string_end ['] (110:56-110:57)
                                ] []] (110:57-110:58)
                            , [,] (110:58-110:59)
                            pair ['published_at': comment['publishedAt']] (111:24-111:62)
                              string ['published_at'] (111:24-111:38)
                                string_start ['] (111:24-111:25)
                                string_content [published_at] (111:25-111:37)
                                string_end ['] (111:37-111:38)
                              : [:] (111:38-111:39)
                              subscript [comment['publishedAt']] (111:40-111:62)
                                identifier [comment] (111:40-111:47)
                                [ [[] (111:47-111:48)
                                string ['publishedAt'] (111:48-111:61)
                                  string_start ['] (111:48-111:49)
                                  string_content [publishedAt] (111:49-111:60)
                                  string_end ['] (111:60-111:61)
                                ] []] (111:61-111:62)
                            } [}] (112:20-112:21)
                      expression_statement [comments.append(comment_data)] (113:20-113:49)
                        call [comments.append(comment_data)] (113:20-113:49)
                          attribute [comments.append] (113:20-113:35)
                            identifier [comments] (113:20-113:28)
                            . [.] (113:28-113:29)
                            identifier [append] (113:29-113:35)
                          argument_list [(comment_data)] (113:35-113:49)
                            ( [(] (113:35-113:36)
                            identifier [comment_data] (113:36-113:48)
                            ) [)] (113:48-113:49)
                  expression_statement [request = self.youtube.commentThreads().list_next(request, response)] (115:16-115:84)
                    assignment [request = self.youtube.commentThreads().list_next(request, response)] (115:16-115:84)
                      identifier [request] (115:16-115:23)
                      = [=] (115:24-115:25)
                      call [self.youtube.commentThreads().list_next(request, response)] (115:26-115:84)
                        attribute [self.youtube.commentThreads().list_next] (115:26-115:65)
                          call [self.youtube.commentThreads()] (115:26-115:55)
                            attribute [self.youtube.commentThreads] (115:26-115:53)
                              attribute [self.youtube] (115:26-115:38)
                                identifier [self] (115:26-115:30)
                                . [.] (115:30-115:31)
                                identifier [youtube] (115:31-115:38)
                              . [.] (115:38-115:39)
                              identifier [commentThreads] (115:39-115:53)
                            argument_list [()] (115:53-115:55)
                              ( [(] (115:53-115:54)
                              ) [)] (115:54-115:55)
                          . [.] (115:55-115:56)
                          identifier [list_next] (115:56-115:65)
                        argument_list [(request, response)] (115:65-115:84)
                          ( [(] (115:65-115:66)
                          identifier [request] (115:66-115:73)
                          , [,] (115:73-115:74)
                          identifier [response] (115:75-115:83)
                          ) [)] (115:83-115:84)
            except_clause [except Exception as e:
            print(f"Error fetching comments: {e}")] (117:8-118:50)
              except [except] (117:8-117:14)
              as_pattern [Exception as e] (117:15-117:29)
                identifier [Exception] (117:15-117:24)
                as [as] (117:25-117:27)
                as_pattern_target [e] (117:28-117:29)
                  identifier [e] (117:28-117:29)
              : [:] (117:29-117:30)
              block [print(f"Error fetching comments: {e}")] (118:12-118:50)
                expression_statement [print(f"Error fetching comments: {e}")] (118:12-118:50)
                  call [print(f"Error fetching comments: {e}")] (118:12-118:50)
                    identifier [print] (118:12-118:17)
                    argument_list [(f"Error fetching comments: {e}")] (118:17-118:50)
                      ( [(] (118:17-118:18)
                      string [f"Error fetching comments: {e}"] (118:18-118:49)
                        string_start [f"] (118:18-118:20)
                        string_content [Error fetching comments: ] (118:20-118:45)
                        interpolation [{e}] (118:45-118:48)
                          { [{] (118:45-118:46)
                          identifier [e] (118:46-118:47)
                          } [}] (118:47-118:48)
                        string_end ["] (118:48-118:49)
                      ) [)] (118:49-118:50)
          return_statement [return comments] (120:8-120:23)
            return [return] (120:8-120:14)
            identifier [comments] (120:15-120:23)
      function_definition [def _save_data(self, data, prefix):
        """Save local copy of data."""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        json_file = self.data_dir / f'{prefix}_{timestamp}.json'
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

        try:
            flat_data = {
                'video_id': data['video_id'],
                'title': data['title'],
                'channel_title': data['channel_title'],
                'view_count': data['view_count'],
                'like_count': data['like_count'],
                'comment_count': data['comment_count'],
                'published_at': data['published_at']
            }

            csv_file = self.data_dir / f'{prefix}_{timestamp}.csv'
            pd.DataFrame([flat_data]).to_csv(csv_file, index=False)

            print(f"Data saved to {json_file} and {csv_file}")
        except Exception as e:
            print(f"Error saving CSV: {e}")] (122:4-146:43)
        def [def] (122:4-122:7)
        identifier [_save_data] (122:8-122:18)
        parameters [(self, data, prefix)] (122:18-122:38)
          ( [(] (122:18-122:19)
          identifier [self] (122:19-122:23)
          , [,] (122:23-122:24)
          identifier [data] (122:25-122:29)
          , [,] (122:29-122:30)
          identifier [prefix] (122:31-122:37)
          ) [)] (122:37-122:38)
        : [:] (122:38-122:39)
        block ["""Save local copy of data."""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        json_file = self.data_dir / f'{prefix}_{timestamp}.json'
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

        try:
            flat_data = {
                'video_id': data['video_id'],
                'title': data['title'],
                'channel_title': data['channel_title'],
                'view_count': data['view_count'],
                'like_count': data['like_count'],
                'comment_count': data['comment_count'],
                'published_at': data['published_at']
            }

            csv_file = self.data_dir / f'{prefix}_{timestamp}.csv'
            pd.DataFrame([flat_data]).to_csv(csv_file, index=False)

            print(f"Data saved to {json_file} and {csv_file}")
        except Exception as e:
            print(f"Error saving CSV: {e}")] (123:8-146:43)
          expression_statement ["""Save local copy of data."""] (123:8-123:38)
            string ["""Save local copy of data."""] (123:8-123:38)
              string_start ["""] (123:8-123:11)
              string_content [Save local copy of data.] (123:11-123:35)
              string_end ["""] (123:35-123:38)
          expression_statement [timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")] (124:8-124:60)
            assignment [timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")] (124:8-124:60)
              identifier [timestamp] (124:8-124:17)
              = [=] (124:18-124:19)
              call [datetime.now().strftime("%Y%m%d_%H%M%S")] (124:20-124:60)
                attribute [datetime.now().strftime] (124:20-124:43)
                  call [datetime.now()] (124:20-124:34)
                    attribute [datetime.now] (124:20-124:32)
                      identifier [datetime] (124:20-124:28)
                      . [.] (124:28-124:29)
                      identifier [now] (124:29-124:32)
                    argument_list [()] (124:32-124:34)
                      ( [(] (124:32-124:33)
                      ) [)] (124:33-124:34)
                  . [.] (124:34-124:35)
                  identifier [strftime] (124:35-124:43)
                argument_list [("%Y%m%d_%H%M%S")] (124:43-124:60)
                  ( [(] (124:43-124:44)
                  string ["%Y%m%d_%H%M%S"] (124:44-124:59)
                    string_start ["] (124:44-124:45)
                    string_content [%Y%m%d_%H%M%S] (124:45-124:58)
                    string_end ["] (124:58-124:59)
                  ) [)] (124:59-124:60)
          expression_statement [json_file = self.data_dir / f'{prefix}_{timestamp}.json'] (126:8-126:64)
            assignment [json_file = self.data_dir / f'{prefix}_{timestamp}.json'] (126:8-126:64)
              identifier [json_file] (126:8-126:17)
              = [=] (126:18-126:19)
              binary_operator [self.data_dir / f'{prefix}_{timestamp}.json'] (126:20-126:64)
                attribute [self.data_dir] (126:20-126:33)
                  identifier [self] (126:20-126:24)
                  . [.] (126:24-126:25)
                  identifier [data_dir] (126:25-126:33)
                / [/] (126:34-126:35)
                string [f'{prefix}_{timestamp}.json'] (126:36-126:64)
                  string_start [f'] (126:36-126:38)
                  interpolation [{prefix}] (126:38-126:46)
                    { [{] (126:38-126:39)
                    identifier [prefix] (126:39-126:45)
                    } [}] (126:45-126:46)
                  string_content [_] (126:46-126:47)
                  interpolation [{timestamp}] (126:47-126:58)
                    { [{] (126:47-126:48)
                    identifier [timestamp] (126:48-126:57)
                    } [}] (126:57-126:58)
                  string_content [.json] (126:58-126:63)
                  string_end ['] (126:63-126:64)
          with_statement [with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)] (127:8-128:60)
            with [with] (127:8-127:12)
            with_clause [open(json_file, 'w', encoding='utf-8') as f] (127:13-127:56)
              with_item [open(json_file, 'w', encoding='utf-8') as f] (127:13-127:56)
                as_pattern [open(json_file, 'w', encoding='utf-8') as f] (127:13-127:56)
                  call [open(json_file, 'w', encoding='utf-8')] (127:13-127:51)
                    identifier [open] (127:13-127:17)
                    argument_list [(json_file, 'w', encoding='utf-8')] (127:17-127:51)
                      ( [(] (127:17-127:18)
                      identifier [json_file] (127:18-127:27)
                      , [,] (127:27-127:28)
                      string ['w'] (127:29-127:32)
                        string_start ['] (127:29-127:30)
                        string_content [w] (127:30-127:31)
                        string_end ['] (127:31-127:32)
                      , [,] (127:32-127:33)
                      keyword_argument [encoding='utf-8'] (127:34-127:50)
                        identifier [encoding] (127:34-127:42)
                        = [=] (127:42-127:43)
                        string ['utf-8'] (127:43-127:50)
                          string_start ['] (127:43-127:44)
                          string_content [utf-8] (127:44-127:49)
                          string_end ['] (127:49-127:50)
                      ) [)] (127:50-127:51)
                  as [as] (127:52-127:54)
                  as_pattern_target [f] (127:55-127:56)
                    identifier [f] (127:55-127:56)
            : [:] (127:56-127:57)
            block [json.dump(data, f, ensure_ascii=False, indent=2)] (128:12-128:60)
              expression_statement [json.dump(data, f, ensure_ascii=False, indent=2)] (128:12-128:60)
                call [json.dump(data, f, ensure_ascii=False, indent=2)] (128:12-128:60)
                  attribute [json.dump] (128:12-128:21)
                    identifier [json] (128:12-128:16)
                    . [.] (128:16-128:17)
                    identifier [dump] (128:17-128:21)
                  argument_list [(data, f, ensure_ascii=False, indent=2)] (128:21-128:60)
                    ( [(] (128:21-128:22)
                    identifier [data] (128:22-128:26)
                    , [,] (128:26-128:27)
                    identifier [f] (128:28-128:29)
                    , [,] (128:29-128:30)
                    keyword_argument [ensure_ascii=False] (128:31-128:49)
                      identifier [ensure_ascii] (128:31-128:43)
                      = [=] (128:43-128:44)
                      false [False] (128:44-128:49)
                    , [,] (128:49-128:50)
                    keyword_argument [indent=2] (128:51-128:59)
                      identifier [indent] (128:51-128:57)
                      = [=] (128:57-128:58)
                      integer [2] (128:58-128:59)
                    ) [)] (128:59-128:60)
          try_statement [try:
            flat_data = {
                'video_id': data['video_id'],
                'title': data['title'],
                'channel_title': data['channel_title'],
                'view_count': data['view_count'],
                'like_count': data['like_count'],
                'comment_count': data['comment_count'],
                'published_at': data['published_at']
            }

            csv_file = self.data_dir / f'{prefix}_{timestamp}.csv'
            pd.DataFrame([flat_data]).to_csv(csv_file, index=False)

            print(f"Data saved to {json_file} and {csv_file}")
        except Exception as e:
            print(f"Error saving CSV: {e}")] (130:8-146:43)
            try [try] (130:8-130:11)
            : [:] (130:11-130:12)
            block [flat_data = {
                'video_id': data['video_id'],
                'title': data['title'],
                'channel_title': data['channel_title'],
                'view_count': data['view_count'],
                'like_count': data['like_count'],
                'comment_count': data['comment_count'],
                'published_at': data['published_at']
            }

            csv_file = self.data_dir / f'{prefix}_{timestamp}.csv'
            pd.DataFrame([flat_data]).to_csv(csv_file, index=False)

            print(f"Data saved to {json_file} and {csv_file}")] (131:12-144:62)
              expression_statement [flat_data = {
                'video_id': data['video_id'],
                'title': data['title'],
                'channel_title': data['channel_title'],
                'view_count': data['view_count'],
                'like_count': data['like_count'],
                'comment_count': data['comment_count'],
                'published_at': data['published_at']
            }] (131:12-139:13)
                assignment [flat_data = {
                'video_id': data['video_id'],
                'title': data['title'],
                'channel_title': data['channel_title'],
                'view_count': data['view_count'],
                'like_count': data['like_count'],
                'comment_count': data['comment_count'],
                'published_at': data['published_at']
            }] (131:12-139:13)
                  identifier [flat_data] (131:12-131:21)
                  = [=] (131:22-131:23)
                  dictionary [{
                'video_id': data['video_id'],
                'title': data['title'],
                'channel_title': data['channel_title'],
                'view_count': data['view_count'],
                'like_count': data['like_count'],
                'comment_count': data['comment_count'],
                'published_at': data['published_at']
            }] (131:24-139:13)
                    { [{] (131:24-131:25)
                    pair ['video_id': data['video_id']] (132:16-132:44)
                      string ['video_id'] (132:16-132:26)
                        string_start ['] (132:16-132:17)
                        string_content [video_id] (132:17-132:25)
                        string_end ['] (132:25-132:26)
                      : [:] (132:26-132:27)
                      subscript [data['video_id']] (132:28-132:44)
                        identifier [data] (132:28-132:32)
                        [ [[] (132:32-132:33)
                        string ['video_id'] (132:33-132:43)
                          string_start ['] (132:33-132:34)
                          string_content [video_id] (132:34-132:42)
                          string_end ['] (132:42-132:43)
                        ] []] (132:43-132:44)
                    , [,] (132:44-132:45)
                    pair ['title': data['title']] (133:16-133:38)
                      string ['title'] (133:16-133:23)
                        string_start ['] (133:16-133:17)
                        string_content [title] (133:17-133:22)
                        string_end ['] (133:22-133:23)
                      : [:] (133:23-133:24)
                      subscript [data['title']] (133:25-133:38)
                        identifier [data] (133:25-133:29)
                        [ [[] (133:29-133:30)
                        string ['title'] (133:30-133:37)
                          string_start ['] (133:30-133:31)
                          string_content [title] (133:31-133:36)
                          string_end ['] (133:36-133:37)
                        ] []] (133:37-133:38)
                    , [,] (133:38-133:39)
                    pair ['channel_title': data['channel_title']] (134:16-134:54)
                      string ['channel_title'] (134:16-134:31)
                        string_start ['] (134:16-134:17)
                        string_content [channel_title] (134:17-134:30)
                        string_end ['] (134:30-134:31)
                      : [:] (134:31-134:32)
                      subscript [data['channel_title']] (134:33-134:54)
                        identifier [data] (134:33-134:37)
                        [ [[] (134:37-134:38)
                        string ['channel_title'] (134:38-134:53)
                          string_start ['] (134:38-134:39)
                          string_content [channel_title] (134:39-134:52)
                          string_end ['] (134:52-134:53)
                        ] []] (134:53-134:54)
                    , [,] (134:54-134:55)
                    pair ['view_count': data['view_count']] (135:16-135:48)
                      string ['view_count'] (135:16-135:28)
                        string_start ['] (135:16-135:17)
                        string_content [view_count] (135:17-135:27)
                        string_end ['] (135:27-135:28)
                      : [:] (135:28-135:29)
                      subscript [data['view_count']] (135:30-135:48)
                        identifier [data] (135:30-135:34)
                        [ [[] (135:34-135:35)
                        string ['view_count'] (135:35-135:47)
                          string_start ['] (135:35-135:36)
                          string_content [view_count] (135:36-135:46)
                          string_end ['] (135:46-135:47)
                        ] []] (135:47-135:48)
                    , [,] (135:48-135:49)
                    pair ['like_count': data['like_count']] (136:16-136:48)
                      string ['like_count'] (136:16-136:28)
                        string_start ['] (136:16-136:17)
                        string_content [like_count] (136:17-136:27)
                        string_end ['] (136:27-136:28)
                      : [:] (136:28-136:29)
                      subscript [data['like_count']] (136:30-136:48)
                        identifier [data] (136:30-136:34)
                        [ [[] (136:34-136:35)
                        string ['like_count'] (136:35-136:47)
                          string_start ['] (136:35-136:36)
                          string_content [like_count] (136:36-136:46)
                          string_end ['] (136:46-136:47)
                        ] []] (136:47-136:48)
                    , [,] (136:48-136:49)
                    pair ['comment_count': data['comment_count']] (137:16-137:54)
                      string ['comment_count'] (137:16-137:31)
                        string_start ['] (137:16-137:17)
                        string_content [comment_count] (137:17-137:30)
                        string_end ['] (137:30-137:31)
                      : [:] (137:31-137:32)
                      subscript [data['comment_count']] (137:33-137:54)
                        identifier [data] (137:33-137:37)
                        [ [[] (137:37-137:38)
                        string ['comment_count'] (137:38-137:53)
                          string_start ['] (137:38-137:39)
                          string_content [comment_count] (137:39-137:52)
                          string_end ['] (137:52-137:53)
                        ] []] (137:53-137:54)
                    , [,] (137:54-137:55)
                    pair ['published_at': data['published_at']] (138:16-138:52)
                      string ['published_at'] (138:16-138:30)
                        string_start ['] (138:16-138:17)
                        string_content [published_at] (138:17-138:29)
                        string_end ['] (138:29-138:30)
                      : [:] (138:30-138:31)
                      subscript [data['published_at']] (138:32-138:52)
                        identifier [data] (138:32-138:36)
                        [ [[] (138:36-138:37)
                        string ['published_at'] (138:37-138:51)
                          string_start ['] (138:37-138:38)
                          string_content [published_at] (138:38-138:50)
                          string_end ['] (138:50-138:51)
                        ] []] (138:51-138:52)
                    } [}] (139:12-139:13)
              expression_statement [csv_file = self.data_dir / f'{prefix}_{timestamp}.csv'] (141:12-141:66)
                assignment [csv_file = self.data_dir / f'{prefix}_{timestamp}.csv'] (141:12-141:66)
                  identifier [csv_file] (141:12-141:20)
                  = [=] (141:21-141:22)
                  binary_operator [self.data_dir / f'{prefix}_{timestamp}.csv'] (141:23-141:66)
                    attribute [self.data_dir] (141:23-141:36)
                      identifier [self] (141:23-141:27)
                      . [.] (141:27-141:28)
                      identifier [data_dir] (141:28-141:36)
                    / [/] (141:37-141:38)
                    string [f'{prefix}_{timestamp}.csv'] (141:39-141:66)
                      string_start [f'] (141:39-141:41)
                      interpolation [{prefix}] (141:41-141:49)
                        { [{] (141:41-141:42)
                        identifier [prefix] (141:42-141:48)
                        } [}] (141:48-141:49)
                      string_content [_] (141:49-141:50)
                      interpolation [{timestamp}] (141:50-141:61)
                        { [{] (141:50-141:51)
                        identifier [timestamp] (141:51-141:60)
                        } [}] (141:60-141:61)
                      string_content [.csv] (141:61-141:65)
                      string_end ['] (141:65-141:66)
              expression_statement [pd.DataFrame([flat_data]).to_csv(csv_file, index=False)] (142:12-142:67)
                call [pd.DataFrame([flat_data]).to_csv(csv_file, index=False)] (142:12-142:67)
                  attribute [pd.DataFrame([flat_data]).to_csv] (142:12-142:44)
                    call [pd.DataFrame([flat_data])] (142:12-142:37)
                      attribute [pd.DataFrame] (142:12-142:24)
                        identifier [pd] (142:12-142:14)
                        . [.] (142:14-142:15)
                        identifier [DataFrame] (142:15-142:24)
                      argument_list [([flat_data])] (142:24-142:37)
                        ( [(] (142:24-142:25)
                        list [[flat_data]] (142:25-142:36)
                          [ [[] (142:25-142:26)
                          identifier [flat_data] (142:26-142:35)
                          ] []] (142:35-142:36)
                        ) [)] (142:36-142:37)
                    . [.] (142:37-142:38)
                    identifier [to_csv] (142:38-142:44)
                  argument_list [(csv_file, index=False)] (142:44-142:67)
                    ( [(] (142:44-142:45)
                    identifier [csv_file] (142:45-142:53)
                    , [,] (142:53-142:54)
                    keyword_argument [index=False] (142:55-142:66)
                      identifier [index] (142:55-142:60)
                      = [=] (142:60-142:61)
                      false [False] (142:61-142:66)
                    ) [)] (142:66-142:67)
              expression_statement [print(f"Data saved to {json_file} and {csv_file}")] (144:12-144:62)
                call [print(f"Data saved to {json_file} and {csv_file}")] (144:12-144:62)
                  identifier [print] (144:12-144:17)
                  argument_list [(f"Data saved to {json_file} and {csv_file}")] (144:17-144:62)
                    ( [(] (144:17-144:18)
                    string [f"Data saved to {json_file} and {csv_file}"] (144:18-144:61)
                      string_start [f"] (144:18-144:20)
                      string_content [Data saved to ] (144:20-144:34)
                      interpolation [{json_file}] (144:34-144:45)
                        { [{] (144:34-144:35)
                        identifier [json_file] (144:35-144:44)
                        } [}] (144:44-144:45)
                      string_content [ and ] (144:45-144:50)
                      interpolation [{csv_file}] (144:50-144:60)
                        { [{] (144:50-144:51)
                        identifier [csv_file] (144:51-144:59)
                        } [}] (144:59-144:60)
                      string_end ["] (144:60-144:61)
                    ) [)] (144:61-144:62)
            except_clause [except Exception as e:
            print(f"Error saving CSV: {e}")] (145:8-146:43)
              except [except] (145:8-145:14)
              as_pattern [Exception as e] (145:15-145:29)
                identifier [Exception] (145:15-145:24)
                as [as] (145:25-145:27)
                as_pattern_target [e] (145:28-145:29)
                  identifier [e] (145:28-145:29)
              : [:] (145:29-145:30)
              block [print(f"Error saving CSV: {e}")] (146:12-146:43)
                expression_statement [print(f"Error saving CSV: {e}")] (146:12-146:43)
                  call [print(f"Error saving CSV: {e}")] (146:12-146:43)
                    identifier [print] (146:12-146:17)
                    argument_list [(f"Error saving CSV: {e}")] (146:17-146:43)
                      ( [(] (146:17-146:18)
                      string [f"Error saving CSV: {e}"] (146:18-146:42)
                        string_start [f"] (146:18-146:20)
                        string_content [Error saving CSV: ] (146:20-146:38)
                        interpolation [{e}] (146:38-146:41)
                          { [{] (146:38-146:39)
                          identifier [e] (146:39-146:40)
                          } [}] (146:40-146:41)
                        string_end ["] (146:41-146:42)
                      ) [)] (146:42-146:43)
